{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DCGAN Training with CSV Spectrogram Data\n",
        "\n",
        "This notebook demonstrates how to train a DCGAN on 128×128 CSV spectrogram windows prepared for solar radio burst generation.\n",
        "\n",
        "**Key Differences from Image-based Training:**\n",
        "- Uses custom `CSVSpectrogramDataset` instead of `ImageFolder`\n",
        "- Loads numerical CSV data instead of PNG/JPG images\n",
        "- Directly processes spectral intensity values\n",
        "- Optimized for 128×128 input (instead of 64×64)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Import custom CSV dataset loader\n",
        "sys.path.append('/Users/remiliascarlet/Desktop/MDP/transfer_learning/dcgan')\n",
        "from csv_spectrogram_dataset import CSVSpectrogramDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set Random Seed for Reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 999  # Set manually for reproducible results\n",
        "print(\"Using Seed: \", seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.use_deterministic_algorithms(True)  # Needed for reproducible results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Hyperparameters and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data root - only use type_3 directory (218 samples)\n",
        "dataroot = \"/Users/remiliascarlet/Desktop/MDP/transfer_learning/burst_data/csv/gan_training_windows_128/type_3/\"\n",
        "\n",
        "# Model checkpoint directory\n",
        "checkpoint_dir = \"./checkpoints_gan_type3\"\n",
        "\n",
        "# Training hyperparameters\n",
        "workers = 2\n",
        "batch_size = 16  # Adjusted for 128×128 images\n",
        "image_size = 128  # CSV files are 128×128\n",
        "nc = 3  # 3 channels (CSV data duplicated to RGB for compatibility)\n",
        "nz = 100  # Latent vector size\n",
        "ngf = 64  # Generator feature map size\n",
        "ndf = 64  # Discriminator feature map size\n",
        "num_epochs = 500  # Number of training epochs\n",
        "lr = 0.0002  # Learning rate for Generator (from DCGAN paper)\n",
        "lr_d = 0.00005  # Lower learning rate for Discriminator (lr/4) to prevent overpowering\n",
        "beta1 = 0.5  # Beta1 for Adam optimizer\n",
        "ngpu = 1  # Number of GPUs (0 for CPU)\n",
        "\n",
        "# Label smoothing parameters (to make discriminator training harder)\n",
        "real_label_smooth = 0.9  # Real labels: 0.9 instead of 1.0\n",
        "fake_label_smooth = 0.1  # Fake labels: 0.1 instead of 0.0\n",
        "\n",
        "# Model saving parameters\n",
        "save_interval = 5  # Save every N epochs (in addition to best model)\n",
        "\n",
        "print(f\"📋 Configuration:\")\n",
        "print(f\"   Data root: {dataroot}\")\n",
        "print(f\"   Checkpoint dir: {checkpoint_dir}\")\n",
        "print(f\"   Image size: {image_size}×{image_size}\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Epochs: {num_epochs}\")\n",
        "print(f\"   Generator LR: {lr}\")\n",
        "print(f\"   Discriminator LR: {lr_d} (reduced to prevent overpowering)\")\n",
        "print(f\"   Label smoothing: Real={real_label_smooth}, Fake={fake_label_smooth}\")\n",
        "print(f\"   Save interval: every {save_interval} epochs\")\n",
        "print(f\"   Training Type 3 bursts only\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load CSV Spectrogram Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the dataset using our custom CSV loader\n",
        "dataset = CSVSpectrogramDataset(\n",
        "    root_dir=dataroot,\n",
        "    normalize_method='minmax',  # Normalize to [-1, 1] for tanh activation\n",
        "    grayscale=False,  # Output 3 channels for RGB compatibility\n",
        "    subsample_ratio=1.0  # Use all data\n",
        ")\n",
        "\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    num_workers=workers\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "print(f\"\\n🖥️  Using device: {device}\")\n",
        "\n",
        "# Plot some training samples\n",
        "real_batch = next(iter(dataloader))\n",
        "print(f\"\\nBatch shape: {real_batch.shape}\")\n",
        "print(f\"Batch value range: [{real_batch.min():.3f}, {real_batch.max():.3f}]\")\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Example Training Spectrograms (Type 3 Bursts)\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[:16].to(device), padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Weight Initialization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom weights initialization called on netG and netD\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Generator Network (128×128 Version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generator for 128×128 images\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # Input: Z (nz=100), going into a convolution\n",
        "            # Output: (ngf*16) x 4 x 4\n",
        "            nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 16),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*16) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*8) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*4) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf*2) x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # State: (ngf) x 64 x 64\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # Final state: (nc=3) x 128 x 128\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "netG.apply(weights_init)\n",
        "print(netG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Discriminator Network (128×128 Version)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Discriminator for 128×128 images\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # Input: (nc=3) x 128 x 128\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf) x 64 x 64\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*2) x 32 x 32\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*4) x 16 x 16\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*8) x 8 x 8\n",
        "            nn.Conv2d(ndf * 8, ndf * 16, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 16),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # State: (ndf*16) x 4 x 4\n",
        "            nn.Conv2d(ndf * 16, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "            # Output: 1 (real/fake probability)\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "netD.apply(weights_init)\n",
        "print(netD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Loss Function and Optimizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the BCELoss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors for visualization\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "# Using label smoothing to make discriminator training harder\n",
        "real_label = real_label_smooth  # 0.9 instead of 1.0\n",
        "fake_label = fake_label_smooth  # 0.1 instead of 0.0\n",
        "\n",
        "# Setup Adam optimizers with different learning rates\n",
        "# Discriminator gets lower learning rate to prevent overpowering Generator\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr_d, betas=(beta1, 0.999))  # Lower LR for D\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))    # Normal LR for G\n",
        "\n",
        "print(\"✅ Loss function and optimizers initialized\")\n",
        "print(f\"   Discriminator LR: {lr_d}\")\n",
        "print(f\"   Generator LR: {lr}\")\n",
        "print(f\"   Label smoothing: Real={real_label}, Fake={fake_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.5 Model Checkpoint Saving Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_gan_checkpoint(netG, netD, optimizerG, optimizerD, epoch, quality_metric, checkpoint_dir):\n",
        "    \"\"\"\n",
        "    Save GAN checkpoint with both Generator and Discriminator.\n",
        "    \n",
        "    Args:\n",
        "        netG: Generator network\n",
        "        netD: Discriminator network\n",
        "        optimizerG: Generator optimizer\n",
        "        optimizerD: Discriminator optimizer\n",
        "        epoch: Current epoch number\n",
        "        quality_metric: Quality metric value (D(G(z)) second value)\n",
        "        checkpoint_dir: Directory to save checkpoints\n",
        "    \"\"\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    \n",
        "    # Filename with epoch and metric\n",
        "    checkpoint_path = os.path.join(\n",
        "        checkpoint_dir, \n",
        "        f\"checkpoint_epoch_{epoch}_quality_{quality_metric:.4f}.pth\"\n",
        "    )\n",
        "    \n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'generator_state_dict': netG.state_dict(),\n",
        "        'discriminator_state_dict': netD.state_dict(),\n",
        "        'optimizerG_state_dict': optimizerG.state_dict(),\n",
        "        'optimizerD_state_dict': optimizerD.state_dict(),\n",
        "        'quality_metric': quality_metric,\n",
        "        'image_size': image_size,\n",
        "        'nz': nz,\n",
        "        'ngf': ngf,\n",
        "        'ndf': ndf,\n",
        "        'nc': nc\n",
        "    }\n",
        "    \n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"💾 Checkpoint saved: epoch {epoch}, quality metric {quality_metric:.4f}\")\n",
        "    print(f\"   Path: {checkpoint_path}\")\n",
        "    \n",
        "    return checkpoint_path\n",
        "\n",
        "print(\"✅ Checkpoint saving function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "D_x_history = []  # Track D(x) over time\n",
        "D_G_z_history = []  # Track D(G(z)) second value over time\n",
        "iters = 0\n",
        "\n",
        "# Best model tracking\n",
        "best_quality_metric = 0.0  # D(G(z)) second value, higher is better\n",
        "best_epoch = 0\n",
        "\n",
        "print(\"🚀 Starting Training Loop with Stabilization Techniques...\")\n",
        "print(f\"Total batches per epoch: {len(dataloader)}\")\n",
        "print(f\"Total iterations: {num_epochs * len(dataloader)}\")\n",
        "print(f\"🔧 Techniques applied:\")\n",
        "print(f\"   - Discriminator LR reduced to {lr_d} (vs {lr} for Generator)\")\n",
        "print(f\"   - Label smoothing: Real labels ~{real_label}, Fake labels ~{fake_label}\")\n",
        "print(f\"   - Random label noise added for robustness\")\n",
        "print(f\"   - Best model tracking based on D(G(z)) quality metric\")\n",
        "print(f\"   - Checkpoints saved to: {checkpoint_dir}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # Track metrics for this epoch\n",
        "    epoch_D_x = []\n",
        "    epoch_D_G_z2 = []  # D(G(z)) second value - quality metric\n",
        "    \n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data.to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        \n",
        "        # Use label smoothing with random noise for more robust training\n",
        "        # Real labels: uniformly sample from [0.8, 1.0] instead of fixed 0.9\n",
        "        label = torch.FloatTensor(b_size).uniform_(0.8, 1.0).to(device)\n",
        "        \n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        \n",
        "        # Fake labels: uniformly sample from [0.0, 0.2] instead of fixed 0.1\n",
        "        label = torch.FloatTensor(b_size).uniform_(0.0, 0.2).to(device)\n",
        "        \n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        # For generator training, use strong real labels (no smoothing)\n",
        "        label = torch.full((b_size,), 1.0, dtype=torch.float, device=device)\n",
        "        # Since we just updated D, perform another forward pass through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Track metrics for this batch\n",
        "        epoch_D_x.append(D_x)\n",
        "        epoch_D_G_z2.append(D_G_z2)\n",
        "        \n",
        "        # Output training stats\n",
        "        if i % 5 == 0:  # Print every 5 batches\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1\n",
        "    \n",
        "    # ===== End of epoch - evaluate and save models =====\n",
        "    avg_D_x = np.mean(epoch_D_x)\n",
        "    avg_D_G_z2 = np.mean(epoch_D_G_z2)  # Quality metric: higher is better (G fools D more)\n",
        "    \n",
        "    D_x_history.append(avg_D_x)\n",
        "    D_G_z_history.append(avg_D_G_z2)\n",
        "    \n",
        "    print(f\"\\n📊 Epoch {epoch} Summary:\")\n",
        "    print(f\"   Avg D(x): {avg_D_x:.4f}\")\n",
        "    print(f\"   Avg D(G(z)) [Quality Metric]: {avg_D_G_z2:.4f}\")\n",
        "    print(f\"   Best Quality so far: {best_quality_metric:.4f} (Epoch {best_epoch})\")\n",
        "    \n",
        "    # Save model if quality improved\n",
        "    if avg_D_G_z2 > best_quality_metric:\n",
        "        improvement = avg_D_G_z2 - best_quality_metric\n",
        "        best_quality_metric = avg_D_G_z2\n",
        "        best_epoch = epoch\n",
        "        \n",
        "        print(f\"🎉 Quality improved by {improvement:.4f}! Saving best model...\")\n",
        "        save_gan_checkpoint(netG, netD, optimizerG, optimizerD, epoch, \n",
        "                          best_quality_metric, checkpoint_dir)\n",
        "    else:\n",
        "        print(f\"⏭️  No improvement (current: {avg_D_G_z2:.4f} vs best: {best_quality_metric:.4f})\")\n",
        "    \n",
        "    # Also save periodically regardless of improvement\n",
        "    if (epoch + 1) % save_interval == 0:\n",
        "        print(f\"💾 Periodic save at epoch {epoch}...\")\n",
        "        periodic_path = os.path.join(checkpoint_dir, f\"periodic_epoch_{epoch}.pth\")\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'generator_state_dict': netG.state_dict(),\n",
        "            'discriminator_state_dict': netD.state_dict(),\n",
        "            'optimizerG_state_dict': optimizerG.state_dict(),\n",
        "            'optimizerD_state_dict': optimizerD.state_dict(),\n",
        "            'quality_metric': avg_D_G_z2,\n",
        "        }\n",
        "        torch.save(checkpoint, periodic_path)\n",
        "        print(f\"   Saved to: {periodic_path}\")\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "\n",
        "print(\"\\n🎉 Training completed!\")\n",
        "print(f\"\\n📊 Final Statistics:\")\n",
        "print(f\"   Best Quality Metric: {best_quality_metric:.4f} (Epoch {best_epoch})\")\n",
        "print(f\"   Total epochs trained: {num_epochs}\")\n",
        "print(f\"   Models saved in: {checkpoint_dir}\")\n",
        "print(f\"\\n💡 Tip: Check generated images in Cell 24 to verify quality!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Plot Training Losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses, label=\"G Loss\")\n",
        "plt.plot(D_losses, label=\"D Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualize Results - Animation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Animation of generator progress\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Final Generated Spectrograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize final generated spectrograms\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Fake Type 3 Radio Burst Spectrograms (Final)\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Real vs Fake Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grab a batch of real images\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot real images\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Type 3 Burst Spectrograms\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[:32].to(device), padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "\n",
        "# Plot fake images\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Fake Type 3 Burst Spectrograms\")\n",
        "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save Trained Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained models\n",
        "torch.save(netG.state_dict(), 'generator_type3_128x128.pth')\n",
        "torch.save(netD.state_dict(), 'discriminator_type3_128x128.pth')\n",
        "print(\"✅ Models saved:\")\n",
        "print(\"   - generator_type3_128x128.pth\")\n",
        "print(\"   - discriminator_type3_128x128.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Generate New Samples from Trained Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate new samples with the trained generator\n",
        "num_samples = 16\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(num_samples, nz, 1, 1, device=device)\n",
        "    generated = netG(noise).cpu()\n",
        "\n",
        "# Visualize newly generated spectrograms\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Newly Generated Type 3 Solar Radio Burst Spectrograms\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(generated, padding=2, normalize=True), (1, 2, 0)))\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Generated {num_samples} new synthetic Type 3 radio burst spectrograms!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
