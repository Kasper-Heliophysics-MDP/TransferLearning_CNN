# SpecGAN Reusable Code Segments for PyTorch Adaptation
# SpecGANå¯å¤ç”¨ä»£ç æ®µåŠPyTorchæ”¹ç¼–æ–¹æ¡ˆ

---

## ğŸ¯ Overview | æ€»è§ˆ

**Total Reusable Components: 7 major segments**
**å¯å¤ç”¨ç»„ä»¶æ€»æ•°ï¼š7ä¸ªä¸»è¦éƒ¨åˆ†**

---

## 1ï¸âƒ£ Generator Architecture (95% Reusable)
## ç”Ÿæˆå™¨æ¶æ„ï¼ˆ95%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `specgan.py`, Lines 47-111

```python
def SpecGANGenerator(z, kernel_len=5, dim=64, use_batchnorm=False, upsample='zeros', train=False):
  # FC and reshape: [100] -> [4, 4, 1024]
  output = tf.layers.dense(z, 4 * 4 * dim * 16)
  output = tf.reshape(output, [batch_size, 4, 4, dim * 16])
  output = batchnorm(output)
  output = tf.nn.relu(output)

  # Layer 0: [4, 4, 1024] -> [8, 8, 512]
  output = tf.layers.conv2d_transpose(output, dim * 8, kernel_len, strides=(2, 2), padding='same')
  output = batchnorm(output)
  output = tf.nn.relu(output)

  # ... repeat for 4 more layers ...

  # Final layer: [64, 64, 64] -> [128, 128, 1]
  output = tf.layers.conv2d_transpose(output, 1, kernel_len, strides=(2, 2), padding='same')
  output = tf.nn.tanh(output)  # Output range: [-1, 1]
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
class SpecGANGenerator(nn.Module):
    """
    Port of SpecGAN Generator from TensorFlow to PyTorch
    Generates 128x128 spectrograms from 100-dim noise vectors
    """
    def __init__(self, nz=100, kernel_len=5, dim=64, use_batchnorm=False, nc=1):
        super(SpecGANGenerator, self).__init__()
        self.nz = nz
        self.dim = dim
        self.use_batchnorm = use_batchnorm
        
        # FC and reshape: [100] -> [4, 4, 1024]
        self.fc = nn.Linear(nz, 4 * 4 * dim * 16)
        
        # Build layers
        layers = []
        
        # Initial batchnorm + relu
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 16))
        layers.append(nn.ReLU(True))
        
        # Layer 0: [4, 4, 1024] -> [8, 8, 512]
        layers.append(nn.ConvTranspose2d(dim * 16, dim * 8, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 8))
        layers.append(nn.ReLU(True))
        
        # Layer 1: [8, 8, 512] -> [16, 16, 256]
        layers.append(nn.ConvTranspose2d(dim * 8, dim * 4, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 4))
        layers.append(nn.ReLU(True))
        
        # Layer 2: [16, 16, 256] -> [32, 32, 128]
        layers.append(nn.ConvTranspose2d(dim * 4, dim * 2, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 2))
        layers.append(nn.ReLU(True))
        
        # Layer 3: [32, 32, 128] -> [64, 64, 64]
        layers.append(nn.ConvTranspose2d(dim * 2, dim, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim))
        layers.append(nn.ReLU(True))
        
        # Layer 4: [64, 64, 64] -> [128, 128, 1]
        layers.append(nn.ConvTranspose2d(dim, nc, kernel_len, stride=2, padding=2))
        layers.append(nn.Tanh())  # Output: [-1, 1]
        
        self.main = nn.Sequential(*layers)
    
    def forward(self, z):
        # z: [N, 100]
        x = self.fc(z)  # [N, 4*4*1024]
        x = x.view(-1, self.dim * 16, 4, 4)  # [N, 1024, 4, 4] - PyTorch channels first!
        x = self.main(x)  # [N, 1, 128, 128]
        return x

# Usage:
netG = SpecGANGenerator(nz=100, kernel_len=5, dim=64, use_batchnorm=False, nc=1)
```

**Conversion Notes | è½¬æ¢è¦ç‚¹:**
- âœ… `tf.layers.dense` â†’ `nn.Linear`
- âœ… `tf.layers.conv2d_transpose` â†’ `nn.ConvTranspose2d`
- âœ… `tf.reshape` â†’ `view()` with **channels-first ordering**
- âœ… Kernel padding adjusted for PyTorch (kernel_len=5 â†’ padding=2)

---

## 2ï¸âƒ£ Discriminator Architecture (95% Reusable)
## åˆ¤åˆ«å™¨æ¶æ„ï¼ˆ95%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `specgan.py`, Lines 122-178

```python
def SpecGANDiscriminator(x, kernel_len=5, dim=64, use_batchnorm=False):
  # Layer 0: [128, 128, 1] -> [64, 64, 64]
  output = tf.layers.conv2d(x, dim, kernel_len, 2, padding='SAME')
  output = lrelu(output)  # LeakyReLU(0.2)

  # ... 4 more conv layers ...

  # Flatten and output
  output = tf.reshape(output, [batch_size, 4 * 4 * dim * 16])
  output = tf.layers.dense(output, 1)[:, 0]
  return output
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
class SpecGANDiscriminator(nn.Module):
    """
    Port of SpecGAN Discriminator from TensorFlow to PyTorch
    Classifies 128x128 spectrograms as real or fake
    """
    def __init__(self, kernel_len=5, dim=64, use_batchnorm=False, nc=1):
        super(SpecGANDiscriminator, self).__init__()
        self.dim = dim
        self.use_batchnorm = use_batchnorm
        
        layers = []
        
        # Layer 0: [128, 128, 1] -> [64, 64, 64]
        layers.append(nn.Conv2d(nc, dim, kernel_len, stride=2, padding=2))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        
        # Layer 1: [64, 64, 64] -> [32, 32, 128]
        layers.append(nn.Conv2d(dim, dim * 2, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 2))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        
        # Layer 2: [32, 32, 128] -> [16, 16, 256]
        layers.append(nn.Conv2d(dim * 2, dim * 4, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 4))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        
        # Layer 3: [16, 16, 256] -> [8, 8, 512]
        layers.append(nn.Conv2d(dim * 4, dim * 8, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 8))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        
        # Layer 4: [8, 8, 512] -> [4, 4, 1024]
        layers.append(nn.Conv2d(dim * 8, dim * 16, kernel_len, stride=2, padding=2))
        if use_batchnorm:
            layers.append(nn.BatchNorm2d(dim * 16))
        layers.append(nn.LeakyReLU(0.2, inplace=True))
        
        self.main = nn.Sequential(*layers)
        
        # Final dense layer
        self.output = nn.Linear(4 * 4 * dim * 16, 1)
    
    def forward(self, x):
        # x: [N, 1, 128, 128]
        x = self.main(x)  # [N, 1024, 4, 4]
        x = x.view(-1, 4 * 4 * self.dim * 16)  # Flatten
        x = self.output(x)  # [N, 1]
        return x.squeeze(1)  # [N]

# Usage:
netD = SpecGANDiscriminator(kernel_len=5, dim=64, use_batchnorm=False, nc=1)
```

**Key Difference | å…³é”®åŒºåˆ«:**
- âœ… SpecGAN uses `kernel_len=5` (5Ã—5 kernels)
- âœ… SpecGANä½¿ç”¨ `kernel_len=5`ï¼ˆ5Ã—5å·ç§¯æ ¸ï¼‰
- âš ï¸ Your DCGAN uses `kernel_len=4` (4Ã—4 kernels)
- âš ï¸ æ‚¨çš„DCGANä½¿ç”¨ `kernel_len=4`ï¼ˆ4Ã—4å·ç§¯æ ¸ï¼‰
- **Recommendation:** Try SpecGAN's 5Ã—5 for better spatial coverage
- **å»ºè®®ï¼š** å°è¯•SpecGANçš„5Ã—5ä»¥è·å¾—æ›´å¥½çš„ç©ºé—´è¦†ç›–

---

## 3ï¸âƒ£ Per-Frequency Normalization (100% Reusable Concept)
## æŒ‰é¢‘ç‡å½’ä¸€åŒ–ï¼ˆ100%å¯å¤ç”¨æ¦‚å¿µï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 31-45

```python
def t_to_f(x, X_mean, X_std):
  """Convert time-domain audio to normalized spectrogram"""
  # Compute STFT
  X = tf.contrib.signal.stft(x[:, :, 0], 256, 128, pad_end=True)
  X = X[:, :, :-1]  # Remove Nyquist bin
  
  # Magnitude
  X_mag = tf.abs(X)
  
  # Log magnitude
  X_lmag = tf.log(X_mag + 1e-6)
  
  # Per-frequency normalization (KEY STEP!)
  X_norm = (X_lmag - X_mean[:-1]) / X_std[:-1]  # X_mean/std: [129] vector
  
  # Clip to 3 standard deviations
  X_norm /= 3.0
  X_norm = tf.clip_by_value(X_norm, -1., 1.)
  
  # Add channel dimension
  X_norm = tf.expand_dims(X_norm, axis=3)  # [N, T, F, 1]
  
  return X_norm
```

---

### **PyTorch Adaptation for CSV Data | PyTorchæ”¹ç¼–ç”¨äºCSVæ•°æ®**

```python
import numpy as np
import torch

class PerFrequencyNormalizer:
    """
    SpecGAN-style per-frequency normalization for CSV spectrograms
    Compute and apply per-frequency bin statistics
    """
    def __init__(self):
        self.mean_per_freq = None
        self.std_per_freq = None
    
    def compute_moments(self, csv_files):
        """
        Compute mean and std for each frequency bin
        Equivalent to SpecGAN's moments() function
        
        Args:
            csv_files: List of CSV file paths
        
        Returns:
            mean_per_freq: [n_freq] array
            std_per_freq: [n_freq] array
        """
        print(f"ğŸ“Š Computing per-frequency moments from {len(csv_files)} files...")
        
        all_specs = []
        for fp in csv_files:
            spec = pd.read_csv(fp, header=None).values  # [128, 128]
            all_specs.append(spec)
        
        all_specs = np.stack(all_specs, axis=0)  # [N, 128, 128]
        print(f"   Data shape: {all_specs.shape}")
        
        # Compute statistics per frequency bin (axis 0 = frequency, axis 2 = time)
        # Average over all samples (axis=0) and all time steps (axis=2)
        self.mean_per_freq = np.mean(all_specs, axis=(0, 2))  # [128]
        self.std_per_freq = np.std(all_specs, axis=(0, 2))    # [128]
        
        print(f"âœ… Per-frequency moments computed:")
        print(f"   Mean range: [{self.mean_per_freq.min():.2f}, {self.mean_per_freq.max():.2f}]")
        print(f"   Std range: [{self.std_per_freq.min():.2f}, {self.std_per_freq.max():.2f}]")
        
        return self.mean_per_freq, self.std_per_freq
    
    def normalize(self, spectrogram):
        """
        Apply per-frequency normalization (SpecGAN-style)
        
        Args:
            spectrogram: [128, 128] numpy array (freq, time)
        
        Returns:
            normalized: [128, 128] numpy array in range [-1, 1]
        """
        if self.mean_per_freq is None or self.std_per_freq is None:
            raise ValueError("Must call compute_moments() first!")
        
        # Expand dimensions for broadcasting
        mean = self.mean_per_freq[:, np.newaxis]  # [128, 1]
        std = self.std_per_freq[:, np.newaxis]    # [128, 1]
        
        # Per-frequency standardization (SpecGAN approach)
        normalized = (spectrogram - mean) / (std + 1e-8)
        
        # Clip to 3 standard deviations (SpecGAN default)
        normalized /= 3.0
        
        # Final clipping to [-1, 1]
        normalized = np.clip(normalized, -1.0, 1.0)
        
        return normalized.astype(np.float32)
    
    def denormalize(self, normalized):
        """Reverse normalization to get original scale"""
        mean = self.mean_per_freq[:, np.newaxis]
        std = self.std_per_freq[:, np.newaxis]
        
        spectrogram = normalized * 3.0  # Undo /3.0
        spectrogram = spectrogram * std + mean
        
        return spectrogram
    
    def save_moments(self, filepath):
        """Save computed moments to file"""
        np.savez(filepath, 
                 mean=self.mean_per_freq, 
                 std=self.std_per_freq)
        print(f"ğŸ’¾ Moments saved to {filepath}")
    
    def load_moments(self, filepath):
        """Load pre-computed moments"""
        data = np.load(filepath)
        self.mean_per_freq = data['mean']
        self.std_per_freq = data['std']
        print(f"ğŸ“‚ Moments loaded from {filepath}")

# Usage example:
normalizer = PerFrequencyNormalizer()
normalizer.compute_moments(csv_files)
normalizer.save_moments('moments.npz')

# In dataset:
spec_normalized = normalizer.normalize(spec_raw)
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**Effort | å·¥ä½œé‡:** 30 minutes | 30åˆ†é’Ÿ  
**Expected Impact | é¢„æœŸå½±å“:** 30-40% quality improvement | è´¨é‡æå‡30-40%

---

## 4ï¸âƒ£ Training Loop with D:G Update Ratio (90% Reusable)
## è®­ç»ƒå¾ªç¯åŠD:Gæ›´æ–°æ¯”ä¾‹ï¼ˆ90%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 278-295

```python
def train(fps, args):
  # ... setup ...
  
  while True:
    # Train discriminator (5 times by default)
    for i in xrange(args.specgan_disc_nupdates):  # Default: 5
      sess.run(D_train_op)
      
      # Clip weights for WGAN
      if D_clip_weights is not None:
        sess.run(D_clip_weights)
    
    # Train generator (once)
    sess.run(G_train_op)
```

**Key Parameters | å…³é”®å‚æ•°:**
```python
# train_specgan.py, Line 656
specgan_disc_nupdates=5  # D updates 5 times per G update
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
# In your training loop (dcgan_csv_training.ipynb):

# Configuration
disc_updates_per_gen = 5  # SpecGAN default

for epoch in range(num_epochs):
    for i, data in enumerate(dataloader, 0):
        
        # ===== Train Discriminator (multiple times) =====
        for d_iter in range(disc_updates_per_gen):
            netD.zero_grad()
            
            # Train on real
            real_cpu = data.to(device)
            label = torch.FloatTensor(b_size).uniform_(0.8, 1.0).to(device)
            output = netD(real_cpu).view(-1)
            errD_real = criterion(output, label)
            errD_real.backward()
            
            # Train on fake
            noise = torch.randn(b_size, nz, 1, 1, device=device)
            fake = netG(noise).detach()  # Detach to avoid G gradients
            label = torch.FloatTensor(b_size).uniform_(0.0, 0.2).to(device)
            output = netD(fake).view(-1)
            errD_fake = criterion(output, label)
            errD_fake.backward()
            
            optimizerD.step()
        
        # ===== Train Generator (once) =====
        netG.zero_grad()
        noise = torch.randn(b_size, nz, 1, 1, device=device)
        fake = netG(noise)
        label = torch.full((b_size,), 1.0, dtype=torch.float, device=device)
        output = netD(fake).view(-1)
        errG = criterion(output, label)
        errG.backward()
        optimizerG.step()
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**Rationale | åŸç†:** Training D more frequently helps balance when G is weak

---

## 5ï¸âƒ£ WGAN-GP Loss (100% Reusable Concept)
## WGAN-GPæŸå¤±ï¼ˆ100%å¯å¤ç”¨æ¦‚å¿µï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 222-236

```python
elif args.specgan_loss == 'wgan-gp':
  # Wasserstein loss
  G_loss = -tf.reduce_mean(D_G_z)
  D_loss = tf.reduce_mean(D_G_z) - tf.reduce_mean(D_x)
  
  # Gradient penalty
  alpha = tf.random_uniform(shape=[batch_size, 1, 1, 1], minval=0., maxval=1.)
  interpolates = x + (alpha * (G_z - x))
  D_interp = SpecGANDiscriminator(interpolates, **d_kwargs)
  
  gradients = tf.gradients(D_interp, [interpolates])[0]
  slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2]))
  gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2.)
  
  LAMBDA = 10
  D_loss += LAMBDA * gradient_penalty
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
def compute_gradient_penalty(netD, real_data, fake_data, device):
    """
    WGAN-GP gradient penalty (from SpecGAN)
    """
    batch_size = real_data.size(0)
    
    # Random interpolation coefficient
    alpha = torch.rand(batch_size, 1, 1, 1, device=device)
    
    # Interpolated samples
    interpolates = alpha * real_data + (1 - alpha) * fake_data
    interpolates.requires_grad_(True)
    
    # Discriminator output on interpolates
    d_interpolates = netD(interpolates)
    
    # Compute gradients
    gradients = torch.autograd.grad(
        outputs=d_interpolates,
        inputs=interpolates,
        grad_outputs=torch.ones_like(d_interpolates),
        create_graph=True,
        retain_graph=True
    )[0]
    
    # Gradient penalty
    gradients = gradients.view(batch_size, -1)
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
    
    return gradient_penalty

# In training loop:
# Wasserstein loss
errD = -torch.mean(D_real) + torch.mean(D_fake)

# Add gradient penalty
LAMBDA = 10
gp = compute_gradient_penalty(netD, real_data, fake_data, device)
errD += LAMBDA * gp

# Generator loss
errG = -torch.mean(D_fake)
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**Advantage | ä¼˜åŠ¿:** Much more stable than standard DCGAN loss!  
**Recommended | æ¨è:** Highly recommended for your small dataset

---

## 6ï¸âƒ£ Moments Computation Logic (80% Reusable)
## çŸ©è®¡ç®—é€»è¾‘ï¼ˆ80%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 575-614

```python
def moments(fps, args):
  """Computes and saves dataset moments (mean/std per frequency)"""
  
  # Load audio and convert to spectrograms
  x_wav = loader.decode_extract_and_batch(fps, ...)
  X = tf.contrib.signal.stft(x_wav, 256, 128, pad_end=True)
  X_mag = tf.abs(X)
  X_lmag = tf.log(X_mag + 1e-6)
  
  # Collect all spectrograms
  _X_lmags = []
  with tf.Session() as sess:
    while True:
      try:
        _X_lmag = sess.run(X_lmag)
        _X_lmags.append(_X_lmag)
      except:
        break
  
  # Concatenate and compute moments
  _X_lmags = np.concatenate(_X_lmags, axis=0)
  mean, std = np.mean(_X_lmags, axis=0), np.std(_X_lmags, axis=0)
  
  # Save moments
  with open(args.data_moments_fp, 'wb') as f:
    pickle.dump((mean, std), f)
```

---

### **PyTorch Adaptation | PyTorchæ”¹ç¼–**

```python
def compute_csv_moments(csv_files, output_path='moments.npz'):
    """
    Compute per-frequency moments for CSV spectrograms
    Adapted from SpecGAN's moments() function
    
    Args:
        csv_files: List of CSV file paths
        output_path: Where to save moments
    
    Returns:
        mean_per_freq: [n_freq] array
        std_per_freq: [n_freq] array
    """
    import pandas as pd
    import numpy as np
    
    print(f"ğŸ“Š Computing per-frequency moments...")
    print(f"   Processing {len(csv_files)} CSV files...")
    
    all_spectrograms = []
    
    for i, fp in enumerate(csv_files):
        if i % 50 == 0:
            print(f"   Progress: {i}/{len(csv_files)}")
        
        # Load CSV (assumes no header, pure numerical data)
        spec = pd.read_csv(fp, header=None).values  # [128, 128]
        
        # Optional: Apply log transform (like SpecGAN)
        # spec = np.log(spec + 1e-6)
        
        all_spectrograms.append(spec)
    
    # Stack all spectrograms: [N_samples, n_freq, n_time]
    all_spectrograms = np.stack(all_spectrograms, axis=0)
    print(f"   Stacked shape: {all_spectrograms.shape}")
    
    # Compute per-frequency statistics
    # axis=0: average over samples
    # axis=2: average over time steps
    # Result: one mean/std per frequency bin
    mean_per_freq = np.mean(all_spectrograms, axis=(0, 2))  # [128]
    std_per_freq = np.std(all_spectrograms, axis=(0, 2))    # [128]
    
    print(f"âœ… Moments computed:")
    print(f"   Mean per freq - shape: {mean_per_freq.shape}, range: [{mean_per_freq.min():.2f}, {mean_per_freq.max():.2f}]")
    print(f"   Std per freq - shape: {std_per_freq.shape}, range: [{std_per_freq.min():.2f}, {std_per_freq.max():.2f}]")
    
    # Save moments
    np.savez(output_path, mean=mean_per_freq, std=std_per_freq)
    print(f"ğŸ’¾ Moments saved to {output_path}")
    
    return mean_per_freq, std_per_freq


# Usage in preprocessing:
import glob

csv_files = glob.glob('/path/to/gan_training_windows_128/type_3/*.csv')
mean, std = compute_csv_moments(csv_files, 'type3_moments.npz')
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­  
**Key Adaptation | å…³é”®æ”¹ç¼–:** Skip STFT (you already have spectrograms)  
**è·³è¿‡STFTï¼ˆæ‚¨å·²ç»æœ‰é¢‘è°±å›¾ï¼‰**

---

## 7ï¸âƒ£ Data Augmentation Strategy (Concept Reusable)
## æ•°æ®å¢å¼ºç­–ç•¥ï¼ˆæ¦‚å¿µå¯å¤ç”¨ï¼‰

### **SpecGAN's Approach | SpecGANçš„æ–¹æ³•**

**File:** `loader.py`, Lines 145-171

```python
def _slice(audio):
  # Random temporal offset
  if slice_randomize_offset:
    start = tf.random_uniform([], maxval=slice_len, dtype=tf.int32)
    audio = audio[start:]
  
  # Extract slices with overlap
  audio_slices = tf.contrib.signal.frame(
      audio,
      slice_len,
      slice_hop,
      pad_end=slice_pad_end
  )
  
  return audio_slices
```

---

### **PyTorch Adaptation for Spectrograms | PyTorchæ”¹ç¼–ç”¨äºé¢‘è°±å›¾**

```python
class SpectrogramAugmentation:
    """
    SpecGAN-inspired augmentation for spectrograms
    """
    @staticmethod
    def temporal_shift(spec, max_shift=30):
        """
        Random temporal shift (like SpecGAN's slice_randomize_offset)
        
        Args:
            spec: [H, W] spectrogram (freq, time)
            max_shift: Maximum shift in time bins
        
        Returns:
            shifted: [H, W] spectrogram
        """
        shift = np.random.randint(-max_shift, max_shift + 1)
        return np.roll(spec, shift, axis=1)  # Roll along time axis
    
    @staticmethod
    def add_noise(spec, noise_std=0.05):
        """
        Add small Gaussian noise for robustness
        """
        noise = np.random.randn(*spec.shape) * noise_std
        return spec + noise
    
    @staticmethod
    def frequency_mask(spec, max_mask_size=10):
        """
        Mask random frequency bands (SpecAugment-style)
        """
        n_freq, n_time = spec.shape
        mask_size = np.random.randint(0, max_mask_size)
        mask_start = np.random.randint(0, n_freq - mask_size)
        
        spec_masked = spec.copy()
        spec_masked[mask_start:mask_start + mask_size, :] = 0
        return spec_masked
    
    @staticmethod
    def time_stretch(spec, rate_range=(0.9, 1.1)):
        """
        Slight time stretching using interpolation
        """
        import cv2
        rate = np.random.uniform(*rate_range)
        new_width = int(spec.shape[1] * rate)
        stretched = cv2.resize(spec, (new_width, spec.shape[0]))
        
        # Crop or pad to original size
        if new_width > spec.shape[1]:
            start = (new_width - spec.shape[1]) // 2
            return stretched[:, start:start + spec.shape[1]]
        else:
            pad = spec.shape[1] - new_width
            return np.pad(stretched, ((0, 0), (pad // 2, pad - pad // 2)))

# Integrate into dataset:
class CSVSpectrogramDataset:
    def __getitem__(self, idx):
        spec = self.load_csv(idx)
        
        if self.augment:
            # Apply SpecGAN-inspired augmentations
            spec = SpectrogramAugmentation.temporal_shift(spec, max_shift=30)
            # Optional: spec = SpectrogramAugmentation.add_noise(spec, 0.05)
        
        spec_normalized = self.normalizer.normalize(spec)
        return torch.from_numpy(spec_normalized).unsqueeze(0)  # [1, 128, 128]
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­  
**Key Idea | å…³é”®æ€æƒ³:** Random temporal shifts to break spatial bias

---

## 8ï¸âƒ£ Loss Function Options (100% Reusable)
## æŸå¤±å‡½æ•°é€‰é¡¹ï¼ˆ100%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 181-238

```python
if args.specgan_loss == 'dcgan':
  # Standard DCGAN loss (BCE)
  G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(
      logits=D_G_z, labels=real))
  D_loss = ...

elif args.specgan_loss == 'lsgan':
  # Least Squares GAN
  G_loss = tf.reduce_mean((D_G_z - 1.) ** 2)
  D_loss = tf.reduce_mean((D_x - 1.) ** 2) + tf.reduce_mean(D_G_z ** 2)
  D_loss /= 2.

elif args.specgan_loss == 'wgan-gp':
  # Wasserstein GAN with Gradient Penalty (RECOMMENDED)
  G_loss = -tf.reduce_mean(D_G_z)
  D_loss = tf.reduce_mean(D_G_z) - tf.reduce_mean(D_x)
  D_loss += LAMBDA * gradient_penalty
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
class GANLoss:
    """Different GAN loss functions (from SpecGAN)"""
    
    @staticmethod
    def dcgan_loss(D_real, D_fake):
        """Standard DCGAN (BCE) loss"""
        criterion = nn.BCEWithLogitsLoss()
        
        real_labels = torch.ones_like(D_real)
        fake_labels = torch.zeros_like(D_fake)
        
        D_loss = criterion(D_real, real_labels) + criterion(D_fake, fake_labels)
        D_loss /= 2.0
        
        G_loss = criterion(D_fake, real_labels)
        
        return G_loss, D_loss
    
    @staticmethod
    def lsgan_loss(D_real, D_fake):
        """Least Squares GAN loss"""
        D_loss = torch.mean((D_real - 1.) ** 2) + torch.mean(D_fake ** 2)
        D_loss /= 2.0
        
        G_loss = torch.mean((D_fake - 1.) ** 2)
        
        return G_loss, D_loss
    
    @staticmethod
    def wgan_gp_loss(D_real, D_fake, netD, real_data, fake_data, device, lambda_gp=10):
        """Wasserstein GAN with Gradient Penalty (RECOMMENDED!)"""
        # Wasserstein distance
        D_loss = torch.mean(D_fake) - torch.mean(D_real)
        G_loss = -torch.mean(D_fake)
        
        # Gradient penalty
        gp = compute_gradient_penalty(netD, real_data, fake_data, device)
        D_loss += lambda_gp * gp
        
        return G_loss, D_loss

# Usage in training loop:
loss_fn = 'wgan-gp'  # or 'dcgan', 'lsgan'

if loss_fn == 'wgan-gp':
    G_loss, D_loss = GANLoss.wgan_gp_loss(
        D_real, D_fake, netD, real_cpu, fake, device, lambda_gp=10
    )
elif loss_fn == 'dcgan':
    G_loss, D_loss = GANLoss.dcgan_loss(D_real, D_fake)
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**SpecGAN Default | SpecGANé»˜è®¤:** WGAN-GP  
**Recommendation | å»ºè®®:** Try WGAN-GP for better stability on small datasets

---

## 9ï¸âƒ£ Optimizer Configuration (100% Reusable)
## ä¼˜åŒ–å™¨é…ç½®ï¼ˆ100%å¯å¤ç”¨ï¼‰

### **SpecGAN TensorFlow Code | SpecGAN TensorFlowä»£ç **

**File:** `train_specgan.py`, Lines 243-270

```python
if args.specgan_loss == 'wgan-gp':
  G_opt = tf.train.AdamOptimizer(
      learning_rate=1e-4,
      beta1=0.5,
      beta2=0.9)
  D_opt = tf.train.AdamOptimizer(
      learning_rate=1e-4,
      beta1=0.5,
      beta2=0.9)
```

---

### **PyTorch Conversion | PyTorchè½¬æ¢**

```python
# SpecGAN's recommended optimizer settings for WGAN-GP:
if loss_type == 'wgan-gp':
    optimizerG = optim.Adam(netG.parameters(), lr=1e-4, betas=(0.5, 0.9))
    optimizerD = optim.Adam(netD.parameters(), lr=1e-4, betas=(0.5, 0.9))

# For standard DCGAN:
elif loss_type == 'dcgan':
    optimizerG = optim.Adam(netG.parameters(), lr=2e-4, betas=(0.5, 0.999))
    optimizerD = optim.Adam(netD.parameters(), lr=2e-4, betas=(0.5, 0.999))
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**Note | æ³¨æ„:** SpecGAN uses equal LR for G and D with WGAN-GP  
**æ³¨æ„ï¼š** SpecGANåœ¨WGAN-GPä¸­å¯¹Gå’ŒDä½¿ç”¨ç›¸åŒå­¦ä¹ ç‡

---

## ğŸ”Ÿ Single-Channel Architecture (Critical!)
## å•é€šé“æ¶æ„ï¼ˆå…³é”®ï¼ï¼‰

### **SpecGAN Design | SpecGANè®¾è®¡**

**Key Observation | å…³é”®è§‚å¯Ÿ:**
```python
# specgan.py, Line 45
"""Output: [None, 128, 128, 1]"""  # Single channel!

# specgan.py, Line 101
output = conv2d_transpose(output, 1, kernel_len, 2, upsample=upsample)
#                                 ^ nc=1, single channel!
```

---

### **Your Current DCGAN Issue | æ‚¨å½“å‰DCGANçš„é—®é¢˜**

```python
# dcgan_csv_training.ipynb, Cell 6
nc = 3  # âŒ You're using 3 channels (RGB)!

# csv_spectrogram_dataset.py
grayscale=False  # âŒ Duplicating to 3 channels
```

**Problem | é—®é¢˜:**
- Spectrograms are inherently **single-channel** (intensity values)
- é¢‘è°±å›¾æœ¬è´¨ä¸Šæ˜¯**å•é€šé“**ï¼ˆå¼ºåº¦å€¼ï¼‰
- Duplicating to 3 channels adds unnecessary parameters
- å¤åˆ¶åˆ°3é€šé“å¢åŠ ä¸å¿…è¦çš„å‚æ•°
- May cause color noise artifacts
- å¯èƒ½å¯¼è‡´å½©è‰²å™ªå£°ä¼ªå½±

---

### **SpecGAN-Aligned Solution | ç¬¦åˆSpecGANçš„è§£å†³æ–¹æ¡ˆ**

```python
# Modify your configuration:
nc = 1  # Single channel (like SpecGAN)

# Modify csv_spectrogram_dataset.py:
dataset = CSVSpectrogramDataset(
    root_dir=dataroot,
    normalize_method='per_frequency',  # New!
    grayscale=True,  # Single channel âœ…
    subsample_ratio=1.0
)

# Generator modification:
class SpecGANGenerator(nn.Module):
    def __init__(self, nz=100, nc=1):  # nc=1 !
        # ... layers ...
        nn.ConvTranspose2d(dim, nc, kernel_len, 2, 2)  # Output: [N, 1, 128, 128]
        nn.Tanh()

# Discriminator modification:
class SpecGANDiscriminator(nn.Module):
    def __init__(self, nc=1):  # nc=1 !
        # ... layers ...
        nn.Conv2d(nc, dim, kernel_len, 2, 2)  # Input: [N, 1, 128, 128]
```

**Reusability | å¯å¤ç”¨æ€§:** â­â­â­â­â­  
**Impact | å½±å“:** May reduce color noise artifacts significantly  
**å¯èƒ½æ˜¾è‘—å‡å°‘å½©è‰²å™ªå£°ä¼ªå½±**

---

## ğŸ“Š Complete Reusability Summary Table | å®Œæ•´å¯å¤ç”¨æ€§æ€»ç»“è¡¨

| Component | SpecGAN File | Lines | Reusability | Effort | Priority |
|-----------|--------------|-------|-------------|--------|----------|
| **1. Generator Architecture**<br>ç”Ÿæˆå™¨æ¶æ„ | `specgan.py` | 47-111 | â­â­â­â­â­ 95% | 1-2 hours | ğŸŸ¢ High |
| **2. Discriminator Architecture**<br>åˆ¤åˆ«å™¨æ¶æ„ | `specgan.py` | 122-178 | â­â­â­â­â­ 95% | 1-2 hours | ğŸŸ¢ High |
| **3. Per-Frequency Normalization**<br>æŒ‰é¢‘ç‡å½’ä¸€åŒ– | `train_specgan.py` | 31-45 | â­â­â­â­â­ 100% | 30 min | ğŸ”´ Critical |
| **4. Moments Computation**<br>çŸ©è®¡ç®— | `train_specgan.py` | 575-614 | â­â­â­â­ 80% | 30 min | ğŸ”´ Critical |
| **5. Training Loop (D:G ratio)**<br>è®­ç»ƒå¾ªç¯ï¼ˆD:Gæ¯”ä¾‹ï¼‰ | `train_specgan.py` | 278-295 | â­â­â­â­â­ 90% | 20 min | ğŸŸ¡ Medium |
| **6. WGAN-GP Loss**<br>WGAN-GPæŸå¤± | `train_specgan.py` | 222-236 | â­â­â­â­â­ 100% | 1 hour | ğŸŸ¡ Medium |
| **7. Temporal Augmentation**<br>æ—¶åºå¢å¼º | `loader.py` | 145-171 | â­â­â­â­ 70% | 20 min | ğŸŸ¢ High |
| **8. Single-Channel Design**<br>å•é€šé“è®¾è®¡ | `specgan.py` | 45, 101 | â­â­â­â­â­ 100% | 10 min | ğŸ”´ Critical |
| **9. Optimizer Settings**<br>ä¼˜åŒ–å™¨è®¾ç½® | `train_specgan.py` | 243-270 | â­â­â­â­â­ 100% | 5 min | ğŸŸ¡ Medium |
| **10. Kernel Size (5Ã—5)**<br>å·ç§¯æ ¸å¤§å° | `specgan.py` | 49 | â­â­â­â­â­ 100% | 5 min | ğŸŸ¡ Medium |

---

## ğŸš« What NOT to Reuse | ä¸è¦å¤ç”¨çš„éƒ¨åˆ†

### **Audio-Specific Components | éŸ³é¢‘ç‰¹å®šç»„ä»¶**

| Component | File | Lines | Reason to Skip |
|-----------|------|-------|----------------|
| **STFT Conversion**<br>STFTè½¬æ¢ | `train_specgan.py` | 33-34 | You already have spectrograms<br>æ‚¨å·²ç»æœ‰é¢‘è°±å›¾ |
| **Griffin-Lim**<br>Griffin-Limç®—æ³• | `train_specgan.py` | 51-83 | No audio reconstruction needed<br>ä¸éœ€è¦éŸ³é¢‘é‡å»º |
| **Audio Loading**<br>éŸ³é¢‘åŠ è½½ | `loader.py` | All | Replace with CSV loading<br>æ›¿æ¢ä¸ºCSVåŠ è½½ |
| **Audio Preview**<br>éŸ³é¢‘é¢„è§ˆ | `train_specgan.py` | 387-460 | Replace with image preview<br>æ›¿æ¢ä¸ºå›¾åƒé¢„è§ˆ |
| **WaveGAN (1D)**<br>1Dæ³¢å½¢GAN | `wavegan.py` | All | Wrong dimensionality<br>ç»´åº¦é”™è¯¯ |

---

## ğŸ’» Concrete Conversion Examples | å…·ä½“è½¬æ¢ç¤ºä¾‹

### **Example 1: Complete Generator Port | ç¤ºä¾‹1ï¼šå®Œæ•´ç”Ÿæˆå™¨ç§»æ¤**

**SpecGAN TensorFlow (Lines 62-102) | TensorFlowä»£ç :**
```python
output = tf.layers.dense(z, 4 * 4 * dim * 16)
output = tf.reshape(output, [batch_size, 4, 4, dim * 16])  # [N, H, W, C]
output = tf.layers.conv2d_transpose(output, dim * 8, 5, strides=(2,2), padding='same')
output = tf.nn.tanh(output)
```

**PyTorch Equivalent | PyTorchç­‰ä»·ä»£ç :**
```python
self.fc = nn.Linear(nz, 4 * 4 * dim * 16)
# In forward:
x = self.fc(z)
x = x.view(-1, dim * 16, 4, 4)  # [N, C, H, W] - PyTorch format!
x = nn.ConvTranspose2d(dim * 16, dim * 8, 5, stride=2, padding=2)(x)
x = torch.tanh(x)
```

**Key Changes | å…³é”®å˜åŒ–:**
- âœ… `tf.layers.dense` â†’ `nn.Linear`
- âœ… `tf.reshape([N,H,W,C])` â†’ `view([N,C,H,W])` **Channelä½ç½®å˜åŒ–ï¼**
- âœ… `tf.layers.conv2d_transpose` â†’ `nn.ConvTranspose2d`
- âœ… `strides=(2,2)` â†’ `stride=2`

---

### **Example 2: Per-Frequency Normalization | ç¤ºä¾‹2ï¼šæŒ‰é¢‘ç‡å½’ä¸€åŒ–**

**SpecGAN TensorFlow (Line 38) | TensorFlowä»£ç :**
```python
X_norm = (X_lmag - X_mean[:-1]) / X_std[:-1]
# X_mean, X_std: shape [129] (per frequency bin)
```

**PyTorch Equivalent | PyTorchç­‰ä»·ä»£ç :**
```python
# In __init__ of dataset:
self.mean_per_freq = mean  # [128]
self.std_per_freq = std    # [128]

# In normalize():
mean = self.mean_per_freq[:, np.newaxis]  # [128, 1] for broadcasting
std = self.std_per_freq[:, np.newaxis]    # [128, 1]
normalized = (spec - mean) / (std + 1e-8)
```

---

### **Example 3: WGAN-GP Gradient Penalty | ç¤ºä¾‹3ï¼šWGAN-GPæ¢¯åº¦æƒ©ç½š**

**SpecGAN TensorFlow (Lines 226-236) | TensorFlowä»£ç :**
```python
alpha = tf.random_uniform(shape=[batch_size, 1, 1, 1], minval=0., maxval=1.)
interpolates = x + (alpha * (G_z - x))
D_interp = SpecGANDiscriminator(interpolates)

gradients = tf.gradients(D_interp, [interpolates])[0]
slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2]))
gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2.)
```

**PyTorch Equivalent | PyTorchç­‰ä»·ä»£ç :**
```python
alpha = torch.rand(batch_size, 1, 1, 1, device=device)
interpolates = real + alpha * (fake - real)
interpolates.requires_grad_(True)

D_interp = netD(interpolates)

gradients = torch.autograd.grad(
    outputs=D_interp,
    inputs=interpolates,
    grad_outputs=torch.ones_like(D_interp),
    create_graph=True,
    retain_graph=True
)[0]

gradients = gradients.view(batch_size, -1)
gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()
```

---

## ğŸ¯ Implementation Priority Guide | å®æ–½ä¼˜å…ˆçº§æŒ‡å—

### **Phase 1: Critical Changes (Total: 1.5 hours) | é˜¶æ®µ1ï¼šå…³é”®ä¿®æ”¹**

1. **Switch to single channel (nc=1)** - 10 min
   - Modify `nc=3` â†’ `nc=1` in notebook
   - Set `grayscale=True` in dataset

2. **Implement per-frequency normalization** - 30 min
   - Add `PerFrequencyNormalizer` class
   - Compute moments from CSV files
   - Apply in dataset loader

3. **Add temporal shift augmentation** - 20 min
   - Implement `temporal_shift()` function
   - Add to dataset `__getitem__`

4. **Change kernel size to 5Ã—5** - 10 min
   - Modify Generator and Discriminator
   - `kernel_len=4` â†’ `kernel_len=5`

5. **Adjust D:G update ratio** - 20 min
   - Train D 5 times per G update
   - Following SpecGAN default

**Expected Improvement | é¢„æœŸæ”¹è¿›:** 40-50% quality increase

---

### **Phase 2: Advanced Improvements (Total: 2 hours) | é˜¶æ®µ2ï¼šè¿›é˜¶æ”¹è¿›**

6. **Implement WGAN-GP loss** - 1 hour
   - Port gradient penalty code
   - Switch from BCE to Wasserstein

7. **Port full SpecGAN architecture** - 1 hour
   - Use exact layer structure from `specgan.py`
   - Match all hyperparameters

**Expected Improvement | é¢„æœŸæ”¹è¿›:** Additional 20-30% (total 60-80%)

---

## ğŸ“‹ Detailed Code Mapping | è¯¦ç»†ä»£ç æ˜ å°„

### **SpecGAN â†’ Your DCGAN Equivalent | å¯¹ç…§è¡¨**

| SpecGAN Code | Location | Your Equivalent | Modification Needed |
|--------------|----------|-----------------|---------------------|
| `SpecGANGenerator` | specgan.py:47 | Your `Generator` class | âœ… Port architecture |
| `SpecGANDiscriminator` | specgan.py:122 | Your `Discriminator` class | âœ… Port architecture |
| `t_to_f()` normalization | train_specgan.py:31 | `normalize()` in dataset | âœ… Add per-freq logic |
| `moments()` computation | train_specgan.py:575 | Pre-processing script | âœ… Adapt for CSV |
| Training D 5x per G | train_specgan.py:287 | Training loop Cell 20 | âœ… Add loop |
| WGAN-GP loss | train_specgan.py:222 | Loss computation | âœ… Port GP code |
| `nc=1` single channel | specgan.py:45,101 | `nc=3` in your code | âœ… Change to 1 |
| `kernel_len=5` | specgan.py:49 | `kernel_size=4` | âœ… Change to 5 |
| `loader.py` | loader.py:68 | `CSVSpectrogramDataset` | âŒ Keep yours, skip audio loading |
| Griffin-Lim `f_to_t()` | train_specgan.py:74 | N/A | âŒ Skip entirely |

---

## ğŸ”§ Quick Implementation Checklist | å¿«é€Ÿå®æ–½æ£€æŸ¥æ¸…å•

### **Minimal Adaptation (Get 60% of benefits in 1.5 hours) | æœ€å°æ”¹ç¼–**

```python
# âœ… Step 1: Change to single channel (5 min)
nc = 1
grayscale = True

# âœ… Step 2: Pre-compute moments (30 min)
normalizer = PerFrequencyNormalizer()
normalizer.compute_moments(csv_files)
normalizer.save_moments('type3_moments.npz')

# âœ… Step 3: Update dataset normalization (20 min)
class CSVSpectrogramDataset:
    def __init__(self, ..., moments_path=None):
        self.normalizer = PerFrequencyNormalizer()
        if moments_path:
            self.normalizer.load_moments(moments_path)
    
    def _normalize(self, spec):
        return self.normalizer.normalize(spec)

# âœ… Step 4: Add temporal augmentation (20 min)
def __getitem__(self, idx):
    spec = self.load_csv(idx)
    if self.augment:
        spec = np.roll(spec, np.random.randint(-30, 30), axis=1)
    return self.normalizer.normalize(spec)

# âœ… Step 5: Change kernel size (10 min)
nn.ConvTranspose2d(..., kernel_size=5, ...)  # Instead of 4

# âœ… Step 6: D:G update ratio (10 min)
for d_iter in range(5):  # Train D 5 times
    # ... train D ...
# Then train G once
```

**Total Time | æ€»æ—¶é—´:** ~1.5 hours  
**Expected Improvement | é¢„æœŸæ”¹è¿›:** 40-60% quality increase

---

### **Full Adaptation (Get 80% benefits in 1 day) | å®Œæ•´æ”¹ç¼–**

Add to above:

```python
# âœ… Step 7: Port exact SpecGAN architecture (2 hours)
# Use code from sections 1ï¸âƒ£ and 2ï¸âƒ£ above

# âœ… Step 8: Implement WGAN-GP (1 hour)
# Use code from section 5ï¸âƒ£ above

# âœ… Step 9: Match all hyperparameters (30 min)
dim = 64          # SpecGAN default
kernel_len = 5    # SpecGAN default
use_batchnorm = False  # SpecGAN default (you're using True)
lr = 1e-4         # For WGAN-GP
beta1, beta2 = 0.5, 0.9  # For WGAN-GP
```

**Total Time | æ€»æ—¶é—´:** ~1 day  
**Expected Improvement | é¢„æœŸæ”¹è¿›:** 60-80% quality increase

---

## ğŸ¯ Recommended Conversion Strategy | æ¨èè½¬æ¢ç­–ç•¥

### **Approach: Incremental Adoption | æ–¹æ³•ï¼šå¢é‡é‡‡ç”¨**

```python
# Week 1: Minimal changes (Phase 1)
# ç¬¬1å‘¨ï¼šæœ€å°æ”¹åŠ¨ï¼ˆé˜¶æ®µ1ï¼‰
âœ… 1. Single channel (nc=1)
âœ… 2. Per-frequency normalization
âœ… 3. Temporal augmentation
âœ… 4. Kernel size = 5

# Week 2: If results good, add advanced features (Phase 2)
# ç¬¬2å‘¨ï¼šå¦‚æœç»“æœå¥½ï¼Œæ·»åŠ é«˜çº§ç‰¹æ€§ï¼ˆé˜¶æ®µ2ï¼‰
âœ… 5. Port full SpecGAN architecture
âœ… 6. Implement WGAN-GP loss
âœ… 7. Adjust D:G update ratio
```

---

## ğŸ“ Key Takeaways | å…³é”®è¦ç‚¹

### **What Makes SpecGAN Different (and Better for You) | SpecGANçš„ç‹¬ç‰¹ä¹‹å¤„ï¼ˆå¯¹æ‚¨æ›´å¥½ï¼‰**

1. **Per-frequency normalization** - NOT global normalization
   - **æŒ‰é¢‘ç‡å½’ä¸€åŒ–** - è€Œéå…¨å±€å½’ä¸€åŒ–
   - Each frequency bin has its own mean/std
   - æ¯ä¸ªé¢‘ç‡binæœ‰è‡ªå·±çš„å‡å€¼/æ ‡å‡†å·®
   - **This is the #1 advantage!**
   - **è¿™æ˜¯ç¬¬ä¸€ä¼˜åŠ¿ï¼**

2. **Single channel** - NOT 3-channel RGB
   - **å•é€šé“** - è€Œé3é€šé“RGB
   - Spectrograms are naturally grayscale
   - é¢‘è°±å›¾å¤©ç„¶æ˜¯ç°åº¦çš„
   - Reduces parameters and potential artifacts
   - å‡å°‘å‚æ•°å’Œæ½œåœ¨ä¼ªå½±

3. **5Ã—5 kernels** - NOT 4Ã—4
   - **5Ã—5å·ç§¯æ ¸** - è€Œé4Ã—4
   - Better spatial receptive field
   - æ›´å¥½çš„ç©ºé—´æ„Ÿå—é‡

4. **WGAN-GP loss option** - NOT just BCE
   - **WGAN-GPæŸå¤±é€‰é¡¹** - ä¸ä»…æ˜¯BCE
   - More stable for small datasets
   - å¯¹å°æ•°æ®é›†æ›´ç¨³å®š

5. **D trains 5x per G** - NOT 1:1 ratio
   - **Dè®­ç»ƒ5æ¬¡å¯¹G1æ¬¡** - è€Œé1:1æ¯”ä¾‹
   - Better balance for spectrogram generation
   - å¯¹é¢‘è°±å›¾ç”Ÿæˆæ›´å¥½çš„å¹³è¡¡

---

## ğŸš€ Ready-to-Use Code Template | å³ç”¨ä»£ç æ¨¡æ¿

I've provided PyTorch conversions for all major components above. Here's what you can directly copy:

æˆ‘å·²ä¸ºä¸Šè¿°æ‰€æœ‰ä¸»è¦ç»„ä»¶æä¾›äº†PyTorchè½¬æ¢ã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯ä»¥ç›´æ¥å¤åˆ¶çš„ï¼š

1. **Section 1**: Complete `SpecGANGenerator` class âœ…
2. **Section 2**: Complete `SpecGANDiscriminator` class âœ…
3. **Section 3**: Complete `PerFrequencyNormalizer` class âœ…
4. **Section 5**: Complete `compute_gradient_penalty()` function âœ…
5. **Section 7**: Complete `SpectrogramAugmentation` class âœ…
6. **Section 8**: Complete `GANLoss` class âœ…

**All code is ready for immediate use!**
**æ‰€æœ‰ä»£ç å¯ç«‹å³ä½¿ç”¨ï¼**

---

## âš¡ Quick Start: Copy-Paste Ready Code | å¿«é€Ÿå¼€å§‹ï¼šå¯ç›´æ¥å¤åˆ¶çš„ä»£ç 

Would you like me to create a complete, ready-to-run notebook that:
1. Uses single-channel architecture
2. Implements per-frequency normalization
3. Adds temporal augmentation
4. Includes WGAN-GP loss option

This would be a drop-in replacement for your current `dcgan_csv_training.ipynb` with all SpecGAN improvements integrated!

éœ€è¦æˆ‘åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„ã€å¯ç›´æ¥è¿è¡Œçš„notebookï¼ŒåŒ…å«ï¼š
1. ä½¿ç”¨å•é€šé“æ¶æ„
2. å®ç°æŒ‰é¢‘ç‡å½’ä¸€åŒ–
3. æ·»åŠ æ—¶åºå¢å¼º
4. åŒ…å«WGAN-GPæŸå¤±é€‰é¡¹

è¿™å°†æ˜¯æ‚¨å½“å‰ `dcgan_csv_training.ipynb` çš„æ›¿ä»£ç‰ˆæœ¬ï¼Œæ•´åˆæ‰€æœ‰SpecGANæ”¹è¿›ï¼

Estimated time to create: **30 minutes**  
é¢„è®¡åˆ›å»ºæ—¶é—´ï¼š**30åˆ†é’Ÿ**

Should I proceed? | æ˜¯å¦å¼€å§‹ï¼Ÿ

