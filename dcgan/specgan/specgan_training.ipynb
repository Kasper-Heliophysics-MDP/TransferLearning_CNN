{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SpecGAN Training for Solar Radio Burst Generation\n",
        "\n",
        "**Based on:** Chris Donahue's SpecGAN (https://github.com/chrisdonahue/wavegan)  \n",
        "**Ported from:** TensorFlow to PyTorch  \n",
        "**Data:** 128×128 CSV spectrogram windows of solar radio bursts\n",
        "\n",
        "**Key SpecGAN Features:**\n",
        "- Per-frequency bin normalization (preserves frequency-specific characteristics)\n",
        "- WGAN-GP loss (more stable training than DCGAN)\n",
        "- Single-channel architecture (matches grayscale spectrograms)\n",
        "- 5×5 kernels (larger receptive field than DCGAN's 4×4)\n",
        "- D:G update ratio of 5:1 (discriminator trains 5 times per generator update)\n",
        "\n",
        "**Prerequisites:**\n",
        "Run `compute_moments.py` BEFORE training to generate moments.npz file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Add paths for local modules\n",
        "sys.path.insert(0, '/Users/remiliascarlet/Desktop/MDP/transfer_learning/dcgan')\n",
        "\n",
        "# Import SpecGAN components\n",
        "from specgan.specgan_models import SpecGANGenerator, SpecGANDiscriminator, weights_init\n",
        "from specgan.specgan_utils import (\n",
        "    PerFrequencyNormalizer, GANLoss, compute_gradient_penalty,\n",
        "    save_gan_checkpoint, load_gan_checkpoint, get_specgan_optimizer,\n",
        "    SPECGAN_DEFAULTS\n",
        ")\n",
        "from csv_spectrogram_dataset import CSVSpectrogramDataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set Random Seed for Reproducibility\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 999\n",
        "print(f\"Using Seed: {seed}\")\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Configuration (SpecGAN Defaults)\n",
        "\n",
        "**From train_specgan.py, Lines 687-712**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data paths\n",
        "dataroot = \"/Users/remiliascarlet/Desktop/MDP/transfer_learning/burst_data/csv/gan_training_windows_128/type_3/\"\n",
        "moments_path = \"./checkpoints_specgan/type3_moments.npz\"\n",
        "checkpoint_dir = \"./checkpoints_specgan\"\n",
        "\n",
        "# SpecGAN architecture defaults (from Lines 697-700)\n",
        "nz = 100              # Latent dimension (specgan_latent_dim)\n",
        "nc = 1                # Number of channels (single-channel spectrogram)\n",
        "kernel_len = 5        # Kernel size (specgan_kernel_len) - 5×5, not 4×4!\n",
        "dim = 64              # Dimension multiplier (specgan_dim)\n",
        "use_batchnorm = False # BatchNorm (specgan_batchnorm) - SpecGAN default is False\n",
        "\n",
        "# Training parameters (from Lines 701-705)\n",
        "disc_nupdates = 5     # D updates per G update (specgan_disc_nupdates) - Important!\n",
        "loss_type = 'wgan-gp' # Loss function (specgan_loss) - WGAN-GP is SpecGAN default\n",
        "batch_size = 16       # Batch size (adjusted from 64 for small dataset)\n",
        "num_epochs = 500      # Number of training epochs\n",
        "workers = 2           # DataLoader workers\n",
        "\n",
        "# Optimizer parameters for WGAN-GP (from Lines 261-269)\n",
        "lr = 1e-4             # Learning rate (both G and D use same LR for WGAN-GP)\n",
        "beta1 = 0.5           # Adam beta1\n",
        "beta2 = 0.9           # Adam beta2\n",
        "\n",
        "# GPU settings\n",
        "ngpu = 1              # Number of GPUs\n",
        "\n",
        "# Model saving\n",
        "save_interval = 5     # Save every N epochs\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SpecGAN Configuration (following original SpecGAN defaults)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Data root: {dataroot}\")\n",
        "print(f\"Moments file: {moments_path}\")\n",
        "print(f\"Checkpoint dir: {checkpoint_dir}\")\n",
        "print(f\"\\nArchitecture (from specgan.py):\")\n",
        "print(f\"  Latent dim (nz): {nz}\")\n",
        "print(f\"  Channels (nc): {nc} (single-channel)\")\n",
        "print(f\"  Kernel size: {kernel_len}×{kernel_len}\")\n",
        "print(f\"  Dimension multiplier: {dim}\")\n",
        "print(f\"  BatchNorm: {use_batchnorm}\")\n",
        "print(f\"\\nTraining (from train_specgan.py):\")\n",
        "print(f\"  Loss type: {loss_type}\")\n",
        "print(f\"  D:G update ratio: {disc_nupdates}:1\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Epochs: {num_epochs}\")\n",
        "print(f\"  Learning rate: {lr}\")\n",
        "print(f\"  Adam betas: ({beta1}, {beta2})\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load Dataset with Per-Frequency Normalization\n",
        "\n",
        "**Uses pre-computed moments from compute_moments.py**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset with SpecGAN features\n",
        "# This replaces SpecGAN's loader.py + t_to_f() normalization\n",
        "dataset = CSVSpectrogramDataset(\n",
        "    root_dir=dataroot,\n",
        "    normalize_method='per_frequency',  # SpecGAN's key feature!\n",
        "    grayscale=True,                    # Single channel (nc=1)\n",
        "    moments_path=moments_path,         # Load pre-computed moments\n",
        "    augment=True,                      # Enable temporal shift augmentation\n",
        "    subsample_ratio=1.0\n",
        ")\n",
        "\n",
        "# Create dataloader\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers,\n",
        "    drop_last=True  # Ensure consistent batch size\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "print(f\"\\n🖥️  Using device: {device}\")\n",
        "\n",
        "# Visualize sample batch\n",
        "print(\"\\n📊 Loading sample batch...\")\n",
        "real_batch = next(iter(dataloader))\n",
        "print(f\"Batch shape: {real_batch.shape}\")  # Should be [batch_size, 1, 128, 128]\n",
        "print(f\"Batch value range: [{real_batch.min():.3f}, {real_batch.max():.3f}]\")\n",
        "print(f\"Expected: [-1, 1] (per-frequency normalized)\")\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Sample Training Spectrograms (Type 3, Per-Frequency Normalized)\")\n",
        "# For single channel, we need to convert [N,1,H,W] to displayable format\n",
        "grid = vutils.make_grid(real_batch[:16].to(device), padding=2, normalize=True, nrow=4)\n",
        "plt.imshow(grid.cpu().permute(1, 2, 0)[:,:,0], cmap='hot')  # Show single channel\n",
        "plt.colorbar()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build Models (SpecGAN Architecture)\n",
        "\n",
        "**From specgan.py: SpecGANGenerator and SpecGANDiscriminator**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Generator\n",
        "# From specgan.py, Lines 47-111\n",
        "netG = SpecGANGenerator(\n",
        "    nz=nz,\n",
        "    kernel_len=kernel_len,\n",
        "    dim=dim,\n",
        "    nc=nc,\n",
        "    use_batchnorm=use_batchnorm,\n",
        "    ngpu=ngpu\n",
        ").to(device)\n",
        "\n",
        "# Create Discriminator  \n",
        "# From specgan.py, Lines 122-178\n",
        "netD = SpecGANDiscriminator(\n",
        "    kernel_len=kernel_len,\n",
        "    dim=dim,\n",
        "    nc=nc,\n",
        "    use_batchnorm=use_batchnorm,\n",
        "    ngpu=ngpu\n",
        ").to(device)\n",
        "\n",
        "# Handle multi-GPU if available\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply weight initialization (DCGAN standard)\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print model summaries (from train_specgan.py, Lines 135-175)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Generator Architecture\")\n",
        "print(\"-\"*70)\n",
        "print(netG)\n",
        "total_params_g = sum(p.numel() for p in netG.parameters())\n",
        "print(f\"Total params: {total_params_g:,} ({total_params_g * 4 / (1024*1024):.2f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"Discriminator Architecture\")\n",
        "print(\"-\"*70)\n",
        "print(netD)\n",
        "total_params_d = sum(p.numel() for p in netD.parameters())\n",
        "print(f\"Total params: {total_params_d:,} ({total_params_d * 4 / (1024*1024):.2f} MB)\")\n",
        "print(\"-\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Setup Optimizers (SpecGAN Recommended Settings)\n",
        "\n",
        "**From train_specgan.py, Lines 261-269 (WGAN-GP settings)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get optimizers based on loss type\n",
        "# Using helper function that implements Lines 243-271\n",
        "optimizerG, optimizerD = get_specgan_optimizer(netG, netD, loss_type=loss_type)\n",
        "\n",
        "# For WGAN-GP (default), both use:\n",
        "# - learning_rate = 1e-4\n",
        "# - beta1 = 0.5, beta2 = 0.9\n",
        "\n",
        "print(\"✅ Optimizers initialized\")\n",
        "print(f\"   Loss type: {loss_type}\")\n",
        "print(f\"   Learning rate: {lr}\")\n",
        "print(f\"   Adam betas: ({beta1}, {beta2})\")\n",
        "\n",
        "# Fixed noise for visualization (similar to SpecGAN's preview)\n",
        "fixed_noise = torch.randn(64, nz, device=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Loop (SpecGAN Training Strategy)\n",
        "\n",
        "**From train_specgan.py, Lines 278-295:**\n",
        "- Train Discriminator `disc_nupdates` times (default: 5)\n",
        "- Then train Generator once\n",
        "- Uses WGAN-GP loss with gradient penalty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training tracking lists\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "D_real_history = []\n",
        "D_fake_history = []\n",
        "iters = 0\n",
        "\n",
        "# Best model tracking\n",
        "best_quality_metric = 0.0  # Track D(G(z)) - higher is better (up to ~0.5)\n",
        "best_epoch = 0\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"Starting SpecGAN Training Loop\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total batches per epoch: {len(dataloader)}\")\n",
        "print(f\"Total iterations: {num_epochs * len(dataloader)}\")\n",
        "print(f\"\\nSpecGAN Training Strategy:\")\n",
        "print(f\"  - Loss: {loss_type}\")\n",
        "print(f\"  - D updates: {disc_nupdates} times per G update\")\n",
        "print(f\"  - Per-frequency normalization: Enabled\")\n",
        "print(f\"  - Temporal augmentation: Enabled\")\n",
        "print(f\"  - Single channel (nc={nc})\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Main training loop\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_D_loss = []\n",
        "    epoch_G_loss = []\n",
        "    epoch_D_real = []\n",
        "    epoch_D_fake = []\n",
        "    \n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        real_data = data.to(device)\n",
        "        b_size = real_data.size(0)\n",
        "        \n",
        "        ############################\n",
        "        # (1) Update D network: Train discriminator multiple times\n",
        "        #     From train_specgan.py, Lines 287-292\n",
        "        ############################\n",
        "        for d_iter in range(disc_nupdates):\n",
        "            netD.zero_grad()\n",
        "            \n",
        "            # Forward pass real batch through D\n",
        "            D_real = netD(real_data)\n",
        "            \n",
        "            # Generate fake batch\n",
        "            noise = torch.randn(b_size, nz, device=device)\n",
        "            fake_data = netG(noise)\n",
        "            \n",
        "            # Forward pass fake batch through D\n",
        "            D_fake = netD(fake_data.detach())\n",
        "            \n",
        "            # Compute loss (WGAN-GP from Lines 222-236)\n",
        "            if loss_type == 'wgan-gp':\n",
        "                # Note: We only compute D_loss here; G_loss computed separately\n",
        "                _, D_loss = GANLoss.wgan_gp_loss(\n",
        "                    D_real, D_fake, netD, real_data, fake_data.detach(), device, lambda_gp=10\n",
        "                )\n",
        "            elif loss_type == 'dcgan':\n",
        "                _, D_loss = GANLoss.dcgan_loss(D_real, D_fake)\n",
        "            elif loss_type == 'lsgan':\n",
        "                _, D_loss = GANLoss.lsgan_loss(D_real, D_fake)\n",
        "            elif loss_type == 'wgan':\n",
        "                _, D_loss = GANLoss.wgan_loss(D_real, D_fake)\n",
        "            \n",
        "            # Backprop and optimize D\n",
        "            D_loss.backward()\n",
        "            optimizerD.step()\n",
        "            \n",
        "            # Weight clipping for vanilla WGAN (not WGAN-GP)\n",
        "            # From Lines 291-292\n",
        "            if loss_type == 'wgan':\n",
        "                from specgan.specgan_utils import clip_discriminator_weights\n",
        "                clip_discriminator_weights(netD, clip_value=0.01)\n",
        "        \n",
        "        ############################\n",
        "        # (2) Update G network: Train generator once\n",
        "        #     From train_specgan.py, Lines 294-295\n",
        "        ############################\n",
        "        netG.zero_grad()\n",
        "        \n",
        "        # Generate new fake batch (don't reuse from D training)\n",
        "        noise = torch.randn(b_size, nz, device=device)\n",
        "        fake_data = netG(noise)\n",
        "        \n",
        "        # Forward through D\n",
        "        D_fake_for_G = netD(fake_data)\n",
        "        \n",
        "        # Compute G loss\n",
        "        if loss_type == 'wgan-gp' or loss_type == 'wgan':\n",
        "            G_loss = -torch.mean(D_fake_for_G)  # Wasserstein\n",
        "        elif loss_type == 'dcgan':\n",
        "            G_loss, _ = GANLoss.dcgan_loss(D_real, D_fake_for_G)\n",
        "        elif loss_type == 'lsgan':\n",
        "            G_loss, _ = GANLoss.lsgan_loss(D_real, D_fake_for_G)\n",
        "        \n",
        "        # Backprop and optimize G\n",
        "        G_loss.backward()\n",
        "        optimizerG.step()\n",
        "        \n",
        "        # Record statistics\n",
        "        D_real_mean = D_real.mean().item()\n",
        "        D_fake_mean = D_fake_for_G.mean().item()\n",
        "        \n",
        "        epoch_D_loss.append(D_loss.item())\n",
        "        epoch_G_loss.append(G_loss.item())\n",
        "        epoch_D_real.append(D_real_mean)\n",
        "        epoch_D_fake.append(D_fake_mean)\n",
        "        \n",
        "        # Save for plotting\n",
        "        G_losses.append(G_loss.item())\n",
        "        D_losses.append(D_loss.item())\n",
        "        \n",
        "        # Output training stats every 5 batches\n",
        "        if i % 5 == 0:\n",
        "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] '\n",
        "                  f'Loss_D: {D_loss.item():.4f} Loss_G: {G_loss.item():.4f} '\n",
        "                  f'D(real): {D_real_mean:.4f} D(fake): {D_fake_mean:.4f}')\n",
        "        \n",
        "        # Save generated images periodically\n",
        "        if (iters % 100 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True, nrow=8))\n",
        "        \n",
        "        iters += 1\n",
        "    \n",
        "    # ===== End of epoch - evaluate and save models =====\n",
        "    avg_D_loss = np.mean(epoch_D_loss)\n",
        "    avg_G_loss = np.mean(epoch_G_loss)\n",
        "    avg_D_real = np.mean(epoch_D_real)\n",
        "    avg_D_fake = np.mean(epoch_D_fake)\n",
        "    \n",
        "    D_real_history.append(avg_D_real)\n",
        "    D_fake_history.append(avg_D_fake)\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Epoch {epoch} Summary:\")\n",
        "    print(f\"  Avg D_loss: {avg_D_loss:.4f}\")\n",
        "    print(f\"  Avg G_loss: {avg_G_loss:.4f}\")\n",
        "    print(f\"  Avg D(real): {avg_D_real:.4f}\")\n",
        "    print(f\"  Avg D(fake): {avg_D_fake:.4f}\")\n",
        "    print(f\"  Best quality so far: {best_quality_metric:.4f} (Epoch {best_epoch})\")\n",
        "    \n",
        "    # Save model if quality improved\n",
        "    # For WGAN-GP, D(fake) closer to 0 is ideal (around 0 means balanced)\n",
        "    # We use abs(D(fake)) as quality metric - lower is better for WGAN\n",
        "    quality_metric = avg_D_fake if loss_type in ['dcgan', 'lsgan'] else -abs(avg_D_fake)\n",
        "    \n",
        "    if quality_metric > best_quality_metric:\n",
        "        improvement = quality_metric - best_quality_metric\n",
        "        best_quality_metric = quality_metric\n",
        "        best_epoch = epoch\n",
        "        \n",
        "        print(f\"  🎉 Quality improved by {improvement:.4f}! Saving checkpoint...\")\n",
        "        save_gan_checkpoint(\n",
        "            netG, netD, optimizerG, optimizerD, epoch, quality_metric,\n",
        "            checkpoint_dir,\n",
        "            hyperparams={'nz': nz, 'nc': nc, 'kernel_len': kernel_len, 'dim': dim}\n",
        "        )\n",
        "    else:\n",
        "        print(f\"  ⏭️  No improvement this epoch\")\n",
        "    \n",
        "    # Periodic save\n",
        "    if (epoch + 1) % save_interval == 0:\n",
        "        periodic_path = os.path.join(checkpoint_dir, f\"periodic_epoch_{epoch}.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'generator_state_dict': netG.state_dict(),\n",
        "            'discriminator_state_dict': netD.state_dict(),\n",
        "            'optimizerG_state_dict': optimizerG.state_dict(),\n",
        "            'optimizerD_state_dict': optimizerD.state_dict(),\n",
        "        }, periodic_path)\n",
        "        print(f\"  💾 Periodic save: {periodic_path}\")\n",
        "    \n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "print(\"\\n✅ Training completed!\")\n",
        "print(f\"Best quality metric: {best_quality_metric:.4f} (Epoch {best_epoch})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss curves\n",
        "axes[0].plot(G_losses, label='G Loss', alpha=0.7)\n",
        "axes[0].plot(D_losses, label='D Loss', alpha=0.7)\n",
        "axes[0].set_xlabel('Iterations')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Generator and Discriminator Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# D(real) and D(fake) curves\n",
        "axes[1].plot(D_real_history, label='D(real)', alpha=0.7)\n",
        "axes[1].plot(D_fake_history, label='D(fake)', alpha=0.7)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.3, label='Target (WGAN)')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Discriminator Output')\n",
        "axes[1].set_title('D(real) and D(fake) Over Training')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Visualize Training Progress (Animation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Animation showing generator progress over time\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# For single-channel images, we need to handle them specially\n",
        "ims = []\n",
        "for img_grid in img_list:\n",
        "    # img_grid is [C, H, W], take first channel for grayscale\n",
        "    im = plt.imshow(img_grid[0].numpy(), animated=True, cmap='hot')\n",
        "    ims.append([im])\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "HTML(ani.to_jshtml())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Final Generated Spectrograms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize final generated spectrograms\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Generated Type 3 Radio Burst Spectrograms (SpecGAN, Final Epoch)\")\n",
        "# Show single-channel image with hot colormap\n",
        "plt.imshow(img_list[-1][0].numpy(), cmap='hot')\n",
        "plt.colorbar(label='Normalized Intensity [-1, 1]')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Real vs Fake Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a batch of real images\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Generate fake images\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(batch_size, nz, device=device)\n",
        "    fake_batch = netG(noise).cpu()\n",
        "\n",
        "# Plot comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "\n",
        "# Real spectrograms\n",
        "axes[0].imshow(vutils.make_grid(real_batch[:16], nrow=4, padding=2, normalize=True)[0].numpy(), cmap='hot')\n",
        "axes[0].set_title(\"Real Type 3 Burst Spectrograms\")\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Fake spectrograms  \n",
        "axes[1].imshow(vutils.make_grid(fake_batch[:16], nrow=4, padding=2, normalize=True)[0].numpy(), cmap='hot')\n",
        "axes[1].set_title(\"Generated (SpecGAN) Type 3 Spectrograms\")\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Generate New Samples from Best Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate new samples with trained generator\n",
        "num_samples = 16\n",
        "\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(num_samples, nz, device=device)\n",
        "    generated = netG(noise).cpu()\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Newly Generated Type 3 Solar Radio Burst Spectrograms (SpecGAN)\")\n",
        "grid = vutils.make_grid(generated, padding=2, normalize=True, nrow=4)\n",
        "plt.imshow(grid[0].numpy(), cmap='hot')  # Single channel\n",
        "plt.colorbar(label='Normalized Intensity')\n",
        "plt.show()\n",
        "\n",
        "print(f\"✅ Generated {num_samples} synthetic Type 3 radio burst spectrograms using SpecGAN!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. SpecGAN vs DCGAN Comparison Summary\n",
        "\n",
        "**Key Improvements from SpecGAN:**\n",
        "1. **Per-frequency normalization** - Each frequency bin normalized independently\n",
        "2. **Single-channel design** - Matches spectrogram data (no artificial RGB)\n",
        "3. **5×5 kernels** - Larger receptive field than DCGAN's 4×4\n",
        "4. **WGAN-GP loss** - More stable training than BCE\n",
        "5. **5:1 D:G ratio** - Discriminator trains more to stay balanced\n",
        "6. **Temporal augmentation** - Random shifts break spatial bias\n",
        "\n",
        "**Expected improvements over original DCGAN:**\n",
        "- Reduced horizontal striping (per-frequency norm handles frequency-dependent noise)\n",
        "- Eliminated left-side concentration (temporal augmentation)\n",
        "- Better stability (WGAN-GP loss)\n",
        "- Cleaner frequency structures (domain-aware normalization)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
