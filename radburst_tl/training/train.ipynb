{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a UNet Model for Solar Radio Burst Segmentation using PyTorch\n",
    "\n",
    "In this notebook, we demonstrate how to train a UNet model for segmenting solar radio bursts using transfer learning. \n",
    "The training is split into two phases:\n",
    "\n",
    "1. **Phase 1:** Freeze the encoder (pre-trained on ImageNet) and train only the decoder.  \n",
    "2. **Phase 2:** Unfreeze the encoder and fine-tune the entire model using a lower learning rate.\n",
    "\n",
    "We use a combined loss function consisting of binary cross-entropy (BCE) loss and a Jaccard (IOU) loss, and we monitor the IOU and F1 metrics on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Enhanced Loss Function Setup\n",
    "\n",
    "This notebook now supports the new enhanced loss function system with:\n",
    "- **Focal Loss**: For handling class imbalance (radio bursts are rare)\n",
    "- **Boundary Loss**: For improving edge detection accuracy\n",
    "- **Adaptive IoU Loss**: For better overlap quality assessment\n",
    "\n",
    "The enhanced loss functions are automatically optimized for solar radio burst detection!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remiliascarlet/Desktop/MDP/transfer_learning/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# üéØ Import enhanced loss function utilities  \n",
    "# from train_utils import (\n",
    "#     create_dataset, build_unet, freeze_encoder_weights, unfreeze_encoder_weights,\n",
    "#     combined_loss, simple_combined_loss, focal_loss, boundary_loss, adaptive_iou_loss,\n",
    "#     compute_metrics, train_one_epoch, validate_one_epoch, adjust_learning_rate, \n",
    "#     save_checkpoint, train_model\n",
    "# )\n",
    "# from loss_config_example import get_loss_config_for_scenario\n",
    "# from loss_tuner import LossTuner, quick_tune\n",
    "\n",
    "# print(\"üéØ Enhanced loss functions loaded successfully!\")\n",
    "\n",
    "# # Show available loss configurations\n",
    "# configs = [\"balanced\", \"imbalanced\", \"noisy\", \"boundary_critical\"]\n",
    "# print(\"üìã Available loss configurations:\")\n",
    "# for config in configs:\n",
    "#     desc = get_loss_config_for_scenario(config)[\"description\"]\n",
    "#     print(f\"  ‚Ä¢ {config}: {desc}\")\n",
    "\n",
    "from train_utils_old import (\n",
    "    create_dataset,\n",
    "    build_unet,\n",
    "    build_deeplabv3,      \n",
    "    build_deeplabv3_rgb_to_mono,\n",
    "    build_model_by_name,\n",
    "    train_model,          \n",
    "    simple_combined_loss\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Loading and Preprocessing\n",
    "\n",
    "We assume that image and mask CSV files are stored in a single directory.\n",
    "The naming convention is as follows:\n",
    "\n",
    "- For burst slices:\n",
    "       slice_20240608_y155_x270406_SkylineHS.csv\n",
    "       slice_20240608_y155_x270406_SkylineHS_mask.csv\n",
    "\n",
    "- For non-burst slices:\n",
    "       slice_20240420_y0_x3391_PeachMountain_2020_nonburst.csv\n",
    "\n",
    "The `create_dataset` function reads the files, normalizes them to [0, 1], and splits the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (1171, 256, 256, 1)\n",
      "Validation images shape: (293, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/remiliascarlet/Desktop/MDP/transfer_learning/burst_data/csv/saved_slices/25spring'\n",
    "\n",
    "(train_images, train_masks), (val_images, val_masks) = create_dataset(data_dir, img_size=(256, 256), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create DataLoaders\n",
    "\n",
    "Convert the numpy arrays into PyTorch tensors and create DataLoaders.\n",
    "\n",
    "We also need to permute dimensions from (N, H, W, C) to (N, C, H, W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert numpy arrays to Torch tensors and permute to (N, channels, H, W)\n",
    "train_images_tensor = torch.tensor(train_images).permute(0, 3, 1, 2)\n",
    "train_masks_tensor  = torch.tensor(train_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "val_images_tensor = torch.tensor(val_images).permute(0, 3, 1, 2)\n",
    "val_masks_tensor  = torch.tensor(val_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images_tensor, train_masks_tensor)\n",
    "val_dataset   = TensorDataset(val_images_tensor, val_masks_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Construction\n",
    "\n",
    "Build a UNet model using the `build_unet` function from the segmentation_models library.\n",
    "\n",
    "Here we set `input_shape=(256,256,1)` for grayscale images, `num_classes=1` for binary segmentation,\n",
    "and use pre-trained ImageNet weights with a ResNet34 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Building DeepLabV3+ with RGB-to-mono conversion\n",
      "   Conversion method: luminance\n",
      "   Encoder: resnet34\n",
      "üì• Loading ImageNet pretrained RGB model...\n",
      "üéØ Creating target single channel model...\n",
      "üîÑ Converting RGB first layer weights using 'luminance' method...\n",
      "   RGB weights shape: torch.Size([64, 3, 7, 7])\n",
      "   Applied luminance-weighted conversion\n",
      "   Converted weights shape: torch.Size([64, 1, 7, 7])\n",
      "üîó Transferring weights...\n",
      "   ‚úÖ Converted: encoder.conv1.weight\n",
      "üìä Weight transfer summary:\n",
      "   ‚úÖ Converted layers: 1\n",
      "   ‚úÖ Transferred layers: 276\n",
      "   ‚ö†Ô∏è Skipped layers: 0\n",
      "üîç Validating converted model...\n",
      "‚úÖ Validation successful:\n",
      "   Input shape: torch.Size([1, 1, 256, 256])\n",
      "   Output shape: torch.Size([1, 1, 256, 256])\n",
      "   Output range: [0.4927, 0.5008]\n",
      "   Total parameters: 22,431,185\n",
      "üéâ RGB-to-mono conversion completed successfully!\n",
      "   Model ready for training on radio burst data\n",
      "DeepLabV3Plus(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): DeepLabV3PlusDecoder(\n",
      "    (aspp): Sequential(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=512, bias=False)\n",
      "              (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=512, bias=False)\n",
      "              (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (3): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=512, bias=False)\n",
      "              (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SeparableConv2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
      "    (block1): Sequential(\n",
      "      (0): Conv2d(64, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): SeparableConv2d(\n",
      "        (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
      "        (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import segmentation_models_pytorch library if not already installed: pip install segmentation-models-pytorch\n",
    "# model = build_unet(input_shape=(256, 256, 1), num_classes=1, encoder_weights='imagenet')\n",
    "# model.to(device)\n",
    "\n",
    "# Build UNet from scratch (no ImageNet)\n",
    "# model = build_unet(\n",
    "#     input_shape=(256, 256, 1), \n",
    "#     num_classes=1, \n",
    "#     encoder_weights=None        # üî• Key: No ImageNet pretraining\n",
    "# )\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "# model = build_deeplabv3(\n",
    "#     input_shape=(256, 256, 1), \n",
    "#     num_classes=1, \n",
    "#     encoder_weights=None,        # üî• Key: No ImageNet pretraining\n",
    "#     encoder_name='resnet34'      # Can change to 'resnet18' for faster training\n",
    "# )\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "model = build_deeplabv3_rgb_to_mono(\n",
    "    input_shape=(256, 256, 1),\n",
    "    num_classes=1,\n",
    "    conversion_method='luminance',  # Use human perception weights\n",
    "    encoder_name='resnet34'         # Can try 'resnet18' for faster training\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting DeepLabV3+ training with simple loss...\n",
      "   Using BCE + IoU loss (no complex focal/boundary loss)\n",
      "   This focuses on pure architecture comparison\n",
      "‚úÖ Simple configuration ready:\n",
      "   Learning rate: 0.001\n",
      "   Training epochs: 100\n",
      "   No encoder freezing (training from scratch)\n",
      "   Using simple BCE + IoU loss\n",
      "üîß Using SIMPLE loss function (BCE + IoU only)\n",
      "   No focal loss, boundary loss, or other enhancements\n",
      "   Good for clean model architecture comparison\n",
      "Phase 1: Freezing encoder and training decoder for 50 epochs.\n",
      "Epoch 1/50 - Train Loss: 1.1220 - Val Loss: 1.0423 - IOU: 0.2383 - F1: 0.2862\n",
      "Checkpoint saved at epoch 1 with best metric 1.0423162893245095 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_1_metric_1.0423.pth\n",
      "Epoch 2/50 - Train Loss: 1.0268 - Val Loss: 1.0102 - IOU: 0.2437 - F1: 0.2895\n",
      "Checkpoint saved at epoch 2 with best metric 1.0102182313015586 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_2_metric_1.0102.pth\n",
      "Epoch 3/50 - Train Loss: 0.9725 - Val Loss: 0.9890 - IOU: 0.2520 - F1: 0.2979\n",
      "Checkpoint saved at epoch 3 with best metric 0.9889926879029525 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_3_metric_0.9890.pth\n",
      "Epoch 4/50 - Train Loss: 0.9644 - Val Loss: 0.9729 - IOU: 0.2650 - F1: 0.3126\n",
      "Checkpoint saved at epoch 4 with best metric 0.9729323920450712 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_4_metric_0.9729.pth\n",
      "Epoch 5/50 - Train Loss: 0.9396 - Val Loss: 0.9990 - IOU: 0.2382 - F1: 0.2868\n",
      "Epoch 6/50 - Train Loss: 0.9144 - Val Loss: 0.9566 - IOU: 0.2669 - F1: 0.3123\n",
      "Checkpoint saved at epoch 6 with best metric 0.9566106357072529 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_6_metric_0.9566.pth\n",
      "Epoch 7/50 - Train Loss: 0.9143 - Val Loss: 0.9884 - IOU: 0.2407 - F1: 0.2870\n",
      "Epoch 8/50 - Train Loss: 0.8862 - Val Loss: 0.9783 - IOU: 0.2634 - F1: 0.3116\n",
      "Epoch 9/50 - Train Loss: 0.8548 - Val Loss: 0.9911 - IOU: 0.2733 - F1: 0.3184\n",
      "Epoch 10/50 - Train Loss: 0.8662 - Val Loss: 1.0084 - IOU: 0.2447 - F1: 0.2940\n",
      "Epoch 11/50 - Train Loss: 0.8569 - Val Loss: 1.0217 - IOU: 0.2423 - F1: 0.2925\n",
      "Early stopping in Phase 1.\n",
      "Phase 2: Unfreezing encoder and fine-tuning entire model.\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 51/100 - Train Loss: 0.9491 - Val Loss: 0.9940 - IOU: 0.2444 - F1: 0.2957\n",
      "Epoch 52/100 - Train Loss: 0.8784 - Val Loss: 0.9317 - IOU: 0.2754 - F1: 0.3179\n",
      "Checkpoint saved at epoch 52 with best metric 0.9317291818167034 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_52_metric_0.9317.pth\n",
      "Epoch 53/100 - Train Loss: 0.8067 - Val Loss: 0.9092 - IOU: 0.2922 - F1: 0.3347\n",
      "Checkpoint saved at epoch 53 with best metric 0.9092253038757726 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_53_metric_0.9092.pth\n",
      "Epoch 54/100 - Train Loss: 0.7793 - Val Loss: 0.8772 - IOU: 0.3010 - F1: 0.3430\n",
      "Checkpoint saved at epoch 54 with best metric 0.8771863517008329 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_54_metric_0.8772.pth\n",
      "Epoch 55/100 - Train Loss: 0.7445 - Val Loss: 0.9369 - IOU: 0.2629 - F1: 0.3045\n",
      "Epoch 56/100 - Train Loss: 0.7232 - Val Loss: 0.8799 - IOU: 0.2988 - F1: 0.3435\n",
      "Epoch 57/100 - Train Loss: 0.7245 - Val Loss: 0.9082 - IOU: 0.2973 - F1: 0.3402\n",
      "Epoch 58/100 - Train Loss: 0.7249 - Val Loss: 0.8662 - IOU: 0.3087 - F1: 0.3510\n",
      "Checkpoint saved at epoch 58 with best metric 0.8662060499191284 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_58_metric_0.8662.pth\n",
      "Epoch 59/100 - Train Loss: 0.6811 - Val Loss: 0.9085 - IOU: 0.2854 - F1: 0.3284\n",
      "Epoch 60/100 - Train Loss: 0.6919 - Val Loss: 0.9448 - IOU: 0.2823 - F1: 0.3256\n",
      "Epoch 61/100 - Train Loss: 0.7130 - Val Loss: 0.9073 - IOU: 0.2924 - F1: 0.3376\n",
      "Epoch 62/100 - Train Loss: 0.6820 - Val Loss: 0.8571 - IOU: 0.3150 - F1: 0.3575\n",
      "Checkpoint saved at epoch 62 with best metric 0.857125881471132 -> ./checkpoints_deeplabv3_rgb_convert/checkpoint_epoch_62_metric_0.8571.pth\n",
      "Epoch 63/100 - Train Loss: 0.6558 - Val Loss: 0.8654 - IOU: 0.3126 - F1: 0.3534\n",
      "Epoch 64/100 - Train Loss: 0.6411 - Val Loss: 0.8734 - IOU: 0.3114 - F1: 0.3516\n",
      "Epoch 65/100 - Train Loss: 0.6392 - Val Loss: 0.8697 - IOU: 0.3045 - F1: 0.3471\n",
      "Epoch 66/100 - Train Loss: 0.6355 - Val Loss: 0.9199 - IOU: 0.2835 - F1: 0.3262\n",
      "Epoch 67/100 - Train Loss: 0.6783 - Val Loss: 0.8657 - IOU: 0.3015 - F1: 0.3443\n",
      "Early stopping in Phase 2.\n",
      "‚úÖ Training completed!\n",
      "   Best validation loss: 0.8571\n",
      "   Best F1 score: 0.3575\n",
      "‚úÖ Training completed!\n",
      "\n",
      "üéØ DeepLabV3+ + Simple Loss Results:\n",
      "   Final F1 Score: 0.3443\n",
      "   Final IoU Score: 0.3015\n",
      "\n",
      "üìà vs UNet+ImageNet baseline:\n",
      "   Baseline F1: 0.3000\n",
      "   DeepLabV3+ F1: 0.3443\n",
      "   Improvement: +0.0443 (14.8%)\n",
      "   ü§î Need investigation - try different backbone or more epochs\n"
     ]
    }
   ],
   "source": [
    "# üöÄ DeepLabV3+ Training with Simple Loss Function\n",
    "print(\"üöÄ Starting DeepLabV3+ training with simple loss...\")\n",
    "print(\"   Using BCE + IoU loss (no complex focal/boundary loss)\")\n",
    "print(\"   This focuses on pure architecture comparison\")\n",
    "\n",
    "# Simple training configuration for DeepLabV3+\n",
    "training_config_simple = {\n",
    "    'initial_lr': 1e-3,       # Standard learning rate\n",
    "    'freeze_epochs': 50,       # No freezing needed (no ImageNet pretraining)\n",
    "    'total_epochs': 100,       # Can be increased for better results\n",
    "    'patience': 5,           \n",
    "    'checkpoint_dir': './checkpoints_deeplabv3_rgb_convert'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Simple configuration ready:\")\n",
    "print(f\"   Learning rate: {training_config_simple['initial_lr']}\")\n",
    "print(f\"   Training epochs: {training_config_simple['total_epochs']}\")\n",
    "print(f\"   No encoder freezing (training from scratch)\")\n",
    "print(f\"   Using simple BCE + IoU loss\")\n",
    "\n",
    "# Train the model with simple loss function\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    initial_lr=training_config_simple['initial_lr'],\n",
    "    freeze_epochs=training_config_simple['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "    total_epochs=training_config_simple['total_epochs'],\n",
    "    checkpoint_dir=training_config_simple['checkpoint_dir'],\n",
    "    patience=training_config_simple['patience'],\n",
    "    device=device\n",
    "    # Ê≥®ÊÑèÔºöÊ≤°Êúâ loss_weights, focal_params Á≠âÂ§çÊùÇÂèÇÊï∞\n",
    "    # Ëá™Âä®‰ΩøÁî® simple_combined_loss (BCE + IoU)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")\n",
    "\n",
    "# üìä Quick Results Analysis\n",
    "if history:\n",
    "    final_metrics = history[-1]\n",
    "    final_f1 = final_metrics.get('val_f1', 0)\n",
    "    final_iou = final_metrics.get('val_iou', 0)\n",
    "    \n",
    "    print(f\"\\nüéØ DeepLabV3+ + Simple Loss Results:\")\n",
    "    print(f\"   Final F1 Score: {final_f1:.4f}\")\n",
    "    print(f\"   Final IoU Score: {final_iou:.4f}\")\n",
    "    \n",
    "    # Compare with your baseline\n",
    "    baseline_f1 = 0.3  # Your UNet result\n",
    "    improvement = final_f1 - baseline_f1\n",
    "    \n",
    "    print(f\"\\nüìà vs UNet+ImageNet baseline:\")\n",
    "    print(f\"   Baseline F1: {baseline_f1:.4f}\")\n",
    "    print(f\"   DeepLabV3+ F1: {final_f1:.4f}\")\n",
    "    print(f\"   Improvement: +{improvement:.4f} ({(improvement/baseline_f1)*100:.1f}%)\")\n",
    "    \n",
    "    if final_f1 > 0.4:\n",
    "        print(\"   üéâ Excellent! Clear architecture improvement\")\n",
    "    elif final_f1 > 0.35:\n",
    "        print(\"   üëç Good improvement! DeepLabV3+ is working\")\n",
    "    else:\n",
    "        print(\"   ü§î Need investigation - try different backbone or more epochs\")\n",
    "else:\n",
    "    print(\"‚ùå No training history available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Enhanced Training with Loss Function Tuning\n",
    "\n",
    "The training functions now automatically use enhanced loss functions optimized for radio burst detection. You can also customize the loss parameters based on your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Loss Function Configuration Options\n",
    "print(\"üéØ Enhanced Loss Function Configuration\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Option 1: Use predefined scenarios (RECOMMENDED)\n",
    "print(\"üìã Option 1: Predefined Scenarios\")\n",
    "scenarios = {\n",
    "    \"imbalanced\": \"Sparse positive samples (recommended for radio bursts)\",  \n",
    "    \"balanced\": \"Roughly balanced positive/negative samples\",\n",
    "    \"noisy\": \"Significant noise and artifacts in data\",\n",
    "    \"boundary_critical\": \"High precision required for edge detection\",\n",
    "    \"original\": \"Use simple BCE+IoU loss (backward compatibility)\"\n",
    "}\n",
    "\n",
    "for scenario, description in scenarios.items():\n",
    "    config = get_loss_config_for_scenario(scenario)\n",
    "    print(f\"  ‚Ä¢ {scenario}: {description}\")\n",
    "    if not config.get('use_simple_loss', False):\n",
    "        print(f\"    Weights: {config['loss_weights']}\")\n",
    "        print(f\"    Focal: {config['focal_params']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Option 2: Custom parameters\n",
    "print(\"üîß Option 2: Custom Parameters\")\n",
    "print(\"  You can specify custom loss_weights and focal_params in train_model()\")\n",
    "print(\"  Example:\")\n",
    "print(\"    loss_weights = {'focal': 1.5, 'iou': 1.2, 'boundary': 0.3}\")\n",
    "print(\"    focal_params = {'alpha': 0.85, 'gamma': 3.0}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Option 3: Auto-tuning based on validation metrics\n",
    "print(\"üìä Option 3: Auto-tuning (Advanced)\")\n",
    "print(\"  Use LossTuner to get suggestions based on validation metrics\")\n",
    "example_metrics = {'precision': 0.85, 'recall': 0.45, 'f1': 0.59, 'iou': 0.42}\n",
    "print(f\"  Example: {example_metrics}\")\n",
    "\n",
    "# Uncomment to use auto-tuning:\n",
    "# tuner = LossTuner()\n",
    "# suggested = tuner.suggest_parameters(example_metrics)\n",
    "# print(f\"  Suggested: {suggested}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ DeepLabV3+ Training Configuration\n",
    "print(\"‚öôÔ∏è Configuring training parameters for DeepLabV3+...\")\n",
    "\n",
    "# Training parameters optimized for DeepLabV3+\n",
    "training_config_deeplabv3 = {\n",
    "    'initial_lr': 1e-3,       # Standard learning rate\n",
    "    'freeze_epochs': 0,       # No freezing needed (no ImageNet)\n",
    "    'total_epochs': 50,       # Can be increased for better results\n",
    "    'patience': 15,           # More patience due to no pretraining\n",
    "    'loss_config': 'imbalanced'  # Use predefined imbalanced configuration\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration ready:\")\n",
    "print(f\"   Loss weights: {loss_config_deeplabv3}\")\n",
    "print(f\"   Training epochs: {training_config_deeplabv3['total_epochs']}\")\n",
    "print(f\"   No encoder freezing (training from scratch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Training with Configurable Loss Parameters\n",
    "# initial_lr = 1e-3\n",
    "# freeze_epochs = 100\n",
    "# total_epochs = 150\n",
    "# patience = 10\n",
    "# checkpoint_dir = './checkpoints_enhanced'\n",
    "\n",
    "print(\"üöÄ Starting Enhanced Training with Configurable Loss...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Choose your training method:\n",
    "\n",
    "# # Method A: Use predefined scenario (RECOMMENDED)\n",
    "# loss_config = \"imbalanced\"  # Choose: \"balanced\", \"imbalanced\", \"noisy\", \"boundary_critical\", \"original\"\n",
    "\n",
    "# train_model(model, train_loader, val_loader, \n",
    "#            initial_lr=initial_lr,\n",
    "#            freeze_epochs=freeze_epochs, \n",
    "#            total_epochs=total_epochs,\n",
    "#            checkpoint_dir=checkpoint_dir, \n",
    "#            patience=patience, \n",
    "#            device=device,\n",
    "#            loss_config=loss_config)\n",
    "\n",
    "# Method B: Use custom parameters (ADVANCED)\n",
    "# custom_loss_weights = {'focal': 1.5, 'iou': 1.2, 'boundary': 0.3}\n",
    "# custom_focal_params = {'alpha': 0.85, 'gamma': 3.0}\n",
    "# \n",
    "# train_model(model, train_loader, val_loader, \n",
    "#            initial_lr=initial_lr,\n",
    "#            freeze_epochs=freeze_epochs, \n",
    "#            total_epochs=total_epochs,\n",
    "#            checkpoint_dir=checkpoint_dir, \n",
    "#            patience=patience, \n",
    "#            device=device,\n",
    "#            loss_weights=custom_loss_weights,\n",
    "#            focal_params=custom_focal_params)\n",
    "\n",
    "# Train with enhanced loss configuration\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    initial_lr=training_config_deeplabv3['initial_lr'],\n",
    "    freeze_epochs=training_config_deeplabv3['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "    total_epochs=training_config_deeplabv3['total_epochs'],\n",
    "    checkpoint_dir='./checkpoints_deeplabv3',  # Separate directory\n",
    "    patience=training_config_deeplabv3['patience'],\n",
    "    device=device,\n",
    "    loss_config=training_config_deeplabv3['loss_config']  # Use imbalanced config\n",
    ")\n",
    "\n",
    "# Method B: Custom DeepLabV3+ parameters (ADVANCED)\n",
    "# custom_loss_weights = {'focal': 0.8, 'iou': 1.0, 'boundary': 0.2}  # Adjust weights\n",
    "# custom_focal_params = {'alpha': 0.85, 'gamma': 2.5}                # Fine-tune focal loss\n",
    "# custom_backbone = 'resnet18'  # 'resnet18', 'resnet34', 'efficientnet-b0'\n",
    "# \n",
    "# # Rebuild model with custom backbone if needed\n",
    "# # model = build_deeplabv3(encoder_name=custom_backbone, encoder_weights=None)\n",
    "# # model.to(device)\n",
    "# \n",
    "# trained_model, history = train_model(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     initial_lr=training_config_deeplabv3['initial_lr'],\n",
    "#     freeze_epochs=training_config_deeplabv3['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "#     total_epochs=training_config_deeplabv3['total_epochs'],\n",
    "#     checkpoint_dir='./checkpoints_deeplabv3',  # Separate directory\n",
    "#     patience=training_config_deeplabv3['patience'],\n",
    "#     device=device,\n",
    "#     loss_weights=custom_loss_weights,\n",
    "#     focal_params=custom_focal_params\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Enhanced vs Original Loss Comparison\n",
    "\n",
    "Load and Evaluate the Best Model\n",
    "\n",
    "After training, load the best saved checkpoint and evaluate the model on the validation set.\n",
    "\n",
    "You can compare the enhanced loss function with the original BCE+IoU loss to see the improvement:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best enhanced model and compare with original loss\n",
    "print(\"üîç Comparing Enhanced vs Original Loss Functions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the enhanced model\n",
    "best_enhanced_path = './checkpoints_enhanced/[your_best_checkpoint].pth'  # Update this path\n",
    "# checkpoint = torch.load(best_enhanced_path, map_location=device)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate with enhanced loss (already loaded)\n",
    "print(\"üìä Enhanced Loss Results:\")\n",
    "val_loss_enhanced, val_metrics_enhanced = validate_one_epoch(model, val_loader, device)\n",
    "print(f\"  Validation Loss: {val_loss_enhanced:.4f}\")\n",
    "print(f\"  IoU: {val_metrics_enhanced['iou']:.4f}\")\n",
    "print(f\"  F1:  {val_metrics_enhanced['f1']:.4f}\")\n",
    "\n",
    "# For comparison, evaluate with original loss\n",
    "print(\"\\\\nüìä Original Loss (BCE+IoU) for comparison:\")\n",
    "model.eval()\n",
    "total_original_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        # Use original simple loss\n",
    "        original_loss = simple_combined_loss(y, preds)\n",
    "        total_original_loss += original_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "avg_original_loss = total_original_loss / num_batches\n",
    "print(f\"  Original Loss: {avg_original_loss:.4f}\")\n",
    "print(f\"  IoU: {val_metrics_enhanced['iou']:.4f} (same model)\")\n",
    "print(f\"  F1:  {val_metrics_enhanced['f1']:.4f} (same model)\")\n",
    "\n",
    "# Show improvement\n",
    "improvement = avg_original_loss - val_loss_enhanced\n",
    "improvement_pct = improvement / avg_original_loss * 100\n",
    "print(f\"\\\\nüéØ Loss Improvement: {improvement:.4f} ({improvement_pct:+.1f}%)\")\n",
    "\n",
    "# Individual loss component analysis\n",
    "print(f\"\\\\nüß© Enhanced Loss Component Breakdown:\")\n",
    "with torch.no_grad():\n",
    "    sample_x, sample_y = next(iter(val_loader))\n",
    "    sample_x, sample_y = sample_x.to(device), sample_y.to(device)\n",
    "    sample_preds = model(sample_x)\n",
    "    \n",
    "    focal_val = focal_loss(sample_preds, sample_y, alpha=0.8, gamma=2.5)\n",
    "    iou_val = adaptive_iou_loss(sample_preds, sample_y, power=1.5)\n",
    "    boundary_val = boundary_loss(sample_preds, sample_y)\n",
    "    \n",
    "    print(f\"  Focal Loss:    {focal_val.item():.4f}\")\n",
    "    print(f\"  IoU Loss:      {iou_val.item():.4f}\")\n",
    "    print(f\"  Boundary Loss: {boundary_val.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
