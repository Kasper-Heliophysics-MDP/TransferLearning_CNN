{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a UNet Model for Solar Radio Burst Segmentation using PyTorch\n",
    "\n",
    "In this notebook, we demonstrate how to train a UNet model for segmenting solar radio bursts using transfer learning. \n",
    "The training is split into two phases:\n",
    "\n",
    "1. **Phase 1:** Freeze the encoder (pre-trained on ImageNet) and train only the decoder.  \n",
    "2. **Phase 2:** Unfreeze the encoder and fine-tune the entire model using a lower learning rate.\n",
    "\n",
    "We use a combined loss function consisting of binary cross-entropy (BCE) loss and a Jaccard (IOU) loss, and we monitor the IOU and F1 metrics on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train_utils import create_dataset, build_unet, freeze_encoder_weights, unfreeze_encoder_weights, combined_loss, compute_metrics, train_one_epoch, validate_one_epoch, adjust_learning_rate, save_checkpoint, train_model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Loading and Preprocessing\n",
    "\n",
    "We assume that image and mask CSV files are stored in a single directory.\n",
    "The naming convention is as follows:\n",
    "\n",
    "- For burst slices:\n",
    "       slice_20240608_y155_x270406_SkylineHS.csv\n",
    "       slice_20240608_y155_x270406_SkylineHS_mask.csv\n",
    "\n",
    "- For non-burst slices:\n",
    "       slice_20240420_y0_x3391_PeachMountain_2020_nonburst.csv\n",
    "\n",
    "The `create_dataset` function reads the files, normalizes them to [0, 1], and splits the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (1171, 256, 256, 1)\n",
      "Validation images shape: (293, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/remiliascarlet/Desktop/MDP/transfer_learning/burst_data/csv/saved_slices/finished'\n",
    "\n",
    "(train_images, train_masks), (val_images, val_masks) = create_dataset(data_dir, img_size=(256, 256), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create DataLoaders\n",
    "\n",
    "Convert the numpy arrays into PyTorch tensors and create DataLoaders.\n",
    "\n",
    "We also need to permute dimensions from (N, H, W, C) to (N, C, H, W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert numpy arrays to Torch tensors and permute to (N, channels, H, W)\n",
    "train_images_tensor = torch.tensor(train_images).permute(0, 3, 1, 2)\n",
    "train_masks_tensor  = torch.tensor(train_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "val_images_tensor = torch.tensor(val_images).permute(0, 3, 1, 2)\n",
    "val_masks_tensor  = torch.tensor(val_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images_tensor, train_masks_tensor)\n",
    "val_dataset   = TensorDataset(val_images_tensor, val_masks_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Construction\n",
    "\n",
    "Build a UNet model using the `build_unet` function from the segmentation_models library.\n",
    "\n",
    "Here we set `input_shape=(256,256,1)` for grayscale images, `num_classes=1` for binary segmentation,\n",
    "and use pre-trained ImageNet weights with a ResNet34 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import segmentation_models_pytorch library if not already installed: pip install segmentation-models-pytorch\n",
    "model = build_unet(input_shape=(256, 256, 1), num_classes=1, encoder_weights='imagenet')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Training the Model\n",
    "\n",
    "We train the model using a two-phase process:\n",
    "\n",
    "    - **Phase 1:** The encoder is frozen for a number of epochs, training only the decoder.\n",
    "\n",
    "    - **Phase 2:** The encoder is unfrozen, the learning rate is reduced, and the entire model is fine-tuned.\n",
    "\n",
    "Early stopping is applied if no improvement is observed for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 1: Freezing encoder and training decoder only.\n",
      "Epoch 1/100 - Train Loss: 1.1444 - Val Loss: 1.0765 - IOU: 0.2106 - F1: 0.2603\n",
      "Checkpoint saved at epoch 1 with best metric 1.0764659517689754 -> ./checkpoints/checkpoint_epoch_1_metric_1.0765.pth\n",
      "Epoch 2/100 - Train Loss: 1.0845 - Val Loss: 1.0514 - IOU: 0.2287 - F1: 0.2766\n",
      "Checkpoint saved at epoch 2 with best metric 1.0514208831285174 -> ./checkpoints/checkpoint_epoch_2_metric_1.0514.pth\n",
      "Epoch 3/100 - Train Loss: 1.0453 - Val Loss: 1.0503 - IOU: 0.2075 - F1: 0.2558\n",
      "Checkpoint saved at epoch 3 with best metric 1.0503181124988354 -> ./checkpoints/checkpoint_epoch_3_metric_1.0503.pth\n",
      "Epoch 4/100 - Train Loss: 1.0225 - Val Loss: 1.0416 - IOU: 0.2253 - F1: 0.2733\n",
      "Checkpoint saved at epoch 4 with best metric 1.041576899980244 -> ./checkpoints/checkpoint_epoch_4_metric_1.0416.pth\n",
      "Epoch 5/100 - Train Loss: 1.0185 - Val Loss: 1.0326 - IOU: 0.2230 - F1: 0.2705\n",
      "Checkpoint saved at epoch 5 with best metric 1.0326249630827653 -> ./checkpoints/checkpoint_epoch_5_metric_1.0326.pth\n",
      "Epoch 6/100 - Train Loss: 0.9982 - Val Loss: 1.0292 - IOU: 0.2314 - F1: 0.2810\n",
      "Checkpoint saved at epoch 6 with best metric 1.0292295750818754 -> ./checkpoints/checkpoint_epoch_6_metric_1.0292.pth\n",
      "Epoch 7/100 - Train Loss: 0.9861 - Val Loss: 1.0694 - IOU: 0.2081 - F1: 0.2549\n",
      "Epoch 8/100 - Train Loss: 0.9912 - Val Loss: 0.9992 - IOU: 0.2471 - F1: 0.2962\n",
      "Checkpoint saved at epoch 8 with best metric 0.9991512047617059 -> ./checkpoints/checkpoint_epoch_8_metric_0.9992.pth\n",
      "Epoch 9/100 - Train Loss: 0.9263 - Val Loss: 1.0314 - IOU: 0.2344 - F1: 0.2849\n",
      "Epoch 10/100 - Train Loss: 0.9214 - Val Loss: 1.0538 - IOU: 0.2215 - F1: 0.2687\n",
      "Epoch 11/100 - Train Loss: 0.9191 - Val Loss: 1.0207 - IOU: 0.2336 - F1: 0.2826\n",
      "Epoch 12/100 - Train Loss: 0.9181 - Val Loss: 1.0781 - IOU: 0.2256 - F1: 0.2750\n",
      "Epoch 13/100 - Train Loss: 0.9352 - Val Loss: 1.0072 - IOU: 0.2561 - F1: 0.3050\n",
      "Epoch 14/100 - Train Loss: 0.8976 - Val Loss: 1.0016 - IOU: 0.2453 - F1: 0.2933\n",
      "Epoch 15/100 - Train Loss: 0.8527 - Val Loss: 1.0247 - IOU: 0.2509 - F1: 0.3002\n",
      "Epoch 16/100 - Train Loss: 0.8680 - Val Loss: 1.0540 - IOU: 0.2390 - F1: 0.2891\n",
      "Epoch 17/100 - Train Loss: 0.8684 - Val Loss: 1.0522 - IOU: 0.2421 - F1: 0.2924\n",
      "Epoch 18/100 - Train Loss: 0.8284 - Val Loss: 1.0368 - IOU: 0.2421 - F1: 0.2888\n",
      "Early stopping in Phase 1.\n",
      "Phase 2: Unfreezing encoder and fine-tuning entire model.\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 101/150 - Train Loss: 0.9580 - Val Loss: 0.9578 - IOU: 0.2640 - F1: 0.3098\n",
      "Checkpoint saved at epoch 101 with best metric 0.957750634143227 -> ./checkpoints/checkpoint_epoch_101_metric_0.9578.pth\n",
      "Epoch 102/150 - Train Loss: 0.8659 - Val Loss: 0.9714 - IOU: 0.2808 - F1: 0.3260\n",
      "Epoch 103/150 - Train Loss: 0.8343 - Val Loss: 0.9483 - IOU: 0.2610 - F1: 0.3085\n",
      "Checkpoint saved at epoch 103 with best metric 0.9482950379973963 -> ./checkpoints/checkpoint_epoch_103_metric_0.9483.pth\n",
      "Epoch 104/150 - Train Loss: 0.7911 - Val Loss: 0.9049 - IOU: 0.2899 - F1: 0.3350\n",
      "Checkpoint saved at epoch 104 with best metric 0.9049327969551086 -> ./checkpoints/checkpoint_epoch_104_metric_0.9049.pth\n",
      "Epoch 105/150 - Train Loss: 0.7677 - Val Loss: 0.9728 - IOU: 0.2656 - F1: 0.3118\n",
      "Epoch 106/150 - Train Loss: 0.7520 - Val Loss: 0.9057 - IOU: 0.2994 - F1: 0.3448\n",
      "Epoch 107/150 - Train Loss: 0.7387 - Val Loss: 0.9017 - IOU: 0.2999 - F1: 0.3438\n",
      "Checkpoint saved at epoch 107 with best metric 0.9016709076730829 -> ./checkpoints/checkpoint_epoch_107_metric_0.9017.pth\n",
      "Epoch 108/150 - Train Loss: 0.7169 - Val Loss: 0.9387 - IOU: 0.2911 - F1: 0.3373\n",
      "Epoch 109/150 - Train Loss: 0.7088 - Val Loss: 0.9132 - IOU: 0.2990 - F1: 0.3443\n",
      "Epoch 110/150 - Train Loss: 0.6830 - Val Loss: 0.9276 - IOU: 0.2940 - F1: 0.3383\n",
      "Epoch 111/150 - Train Loss: 0.6867 - Val Loss: 0.9330 - IOU: 0.3020 - F1: 0.3477\n",
      "Epoch 112/150 - Train Loss: 0.6685 - Val Loss: 0.9373 - IOU: 0.2889 - F1: 0.3335\n",
      "Epoch 113/150 - Train Loss: 0.6906 - Val Loss: 0.9387 - IOU: 0.2878 - F1: 0.3325\n",
      "Epoch 114/150 - Train Loss: 0.6711 - Val Loss: 0.8990 - IOU: 0.3010 - F1: 0.3452\n",
      "Checkpoint saved at epoch 114 with best metric 0.8990201322655929 -> ./checkpoints/checkpoint_epoch_114_metric_0.8990.pth\n",
      "Epoch 115/150 - Train Loss: 0.6562 - Val Loss: 0.8982 - IOU: 0.3032 - F1: 0.3478\n",
      "Checkpoint saved at epoch 115 with best metric 0.8982476937143427 -> ./checkpoints/checkpoint_epoch_115_metric_0.8982.pth\n",
      "Epoch 116/150 - Train Loss: 0.6548 - Val Loss: 0.9338 - IOU: 0.3012 - F1: 0.3453\n",
      "Epoch 117/150 - Train Loss: 0.6503 - Val Loss: 0.8951 - IOU: 0.3056 - F1: 0.3479\n",
      "Checkpoint saved at epoch 117 with best metric 0.8950732789541546 -> ./checkpoints/checkpoint_epoch_117_metric_0.8951.pth\n",
      "Epoch 118/150 - Train Loss: 0.6592 - Val Loss: 0.8958 - IOU: 0.3046 - F1: 0.3501\n",
      "Epoch 119/150 - Train Loss: 0.6443 - Val Loss: 0.8997 - IOU: 0.3051 - F1: 0.3486\n",
      "Epoch 120/150 - Train Loss: 0.6536 - Val Loss: 0.9041 - IOU: 0.3051 - F1: 0.3467\n",
      "Epoch 121/150 - Train Loss: 0.6339 - Val Loss: 0.8785 - IOU: 0.3133 - F1: 0.3529\n",
      "Checkpoint saved at epoch 121 with best metric 0.8785325539739508 -> ./checkpoints/checkpoint_epoch_121_metric_0.8785.pth\n",
      "Epoch 122/150 - Train Loss: 0.6433 - Val Loss: 0.8956 - IOU: 0.3082 - F1: 0.3489\n",
      "Epoch 123/150 - Train Loss: 0.6154 - Val Loss: 0.8815 - IOU: 0.3102 - F1: 0.3498\n",
      "Epoch 124/150 - Train Loss: 0.6362 - Val Loss: 0.8923 - IOU: 0.3152 - F1: 0.3558\n",
      "Epoch 125/150 - Train Loss: 0.6146 - Val Loss: 0.9086 - IOU: 0.3085 - F1: 0.3508\n",
      "Epoch 126/150 - Train Loss: 0.6254 - Val Loss: 0.9062 - IOU: 0.3140 - F1: 0.3540\n",
      "Epoch 127/150 - Train Loss: 0.6509 - Val Loss: 0.9061 - IOU: 0.3076 - F1: 0.3482\n",
      "Epoch 128/150 - Train Loss: 0.6395 - Val Loss: 0.8513 - IOU: 0.3308 - F1: 0.3689\n",
      "Checkpoint saved at epoch 128 with best metric 0.8512583563202306 -> ./checkpoints/checkpoint_epoch_128_metric_0.8513.pth\n",
      "Epoch 129/150 - Train Loss: 0.6088 - Val Loss: 0.8972 - IOU: 0.3185 - F1: 0.3563\n",
      "Epoch 130/150 - Train Loss: 0.6067 - Val Loss: 0.8838 - IOU: 0.3172 - F1: 0.3578\n",
      "Epoch 131/150 - Train Loss: 0.6080 - Val Loss: 0.8742 - IOU: 0.3220 - F1: 0.3615\n",
      "Epoch 132/150 - Train Loss: 0.6052 - Val Loss: 0.8774 - IOU: 0.3216 - F1: 0.3620\n",
      "Epoch 133/150 - Train Loss: 0.5962 - Val Loss: 0.8825 - IOU: 0.3236 - F1: 0.3643\n",
      "Epoch 134/150 - Train Loss: 0.6106 - Val Loss: 0.9158 - IOU: 0.3096 - F1: 0.3501\n",
      "Epoch 135/150 - Train Loss: 0.6933 - Val Loss: 0.9167 - IOU: 0.3090 - F1: 0.3513\n",
      "Epoch 136/150 - Train Loss: 0.6337 - Val Loss: 0.8454 - IOU: 0.3311 - F1: 0.3702\n",
      "Checkpoint saved at epoch 136 with best metric 0.8453685609917891 -> ./checkpoints/checkpoint_epoch_136_metric_0.8454.pth\n",
      "Epoch 137/150 - Train Loss: 0.6000 - Val Loss: 0.8345 - IOU: 0.3339 - F1: 0.3728\n",
      "Checkpoint saved at epoch 137 with best metric 0.8345032961745011 -> ./checkpoints/checkpoint_epoch_137_metric_0.8345.pth\n",
      "Epoch 138/150 - Train Loss: 0.5888 - Val Loss: 0.8427 - IOU: 0.3357 - F1: 0.3737\n",
      "Epoch 139/150 - Train Loss: 0.5869 - Val Loss: 0.8682 - IOU: 0.3278 - F1: 0.3677\n",
      "Epoch 140/150 - Train Loss: 0.5810 - Val Loss: 0.8766 - IOU: 0.3282 - F1: 0.3695\n",
      "Epoch 141/150 - Train Loss: 0.5726 - Val Loss: 0.8915 - IOU: 0.3256 - F1: 0.3660\n",
      "Epoch 142/150 - Train Loss: 0.5722 - Val Loss: 0.8595 - IOU: 0.3348 - F1: 0.3722\n",
      "Epoch 143/150 - Train Loss: 0.5985 - Val Loss: 0.8860 - IOU: 0.3312 - F1: 0.3698\n",
      "Epoch 144/150 - Train Loss: 0.5945 - Val Loss: 0.9262 - IOU: 0.3081 - F1: 0.3485\n",
      "Epoch 145/150 - Train Loss: 0.6018 - Val Loss: 0.9353 - IOU: 0.3172 - F1: 0.3583\n",
      "Epoch 146/150 - Train Loss: 0.5943 - Val Loss: 0.8691 - IOU: 0.3313 - F1: 0.3687\n",
      "Epoch 147/150 - Train Loss: 0.5856 - Val Loss: 0.8622 - IOU: 0.3349 - F1: 0.3726\n",
      "Early stopping in Phase 2.\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 1e-3\n",
    "freeze_epochs = 100    # Adjust as needed.\n",
    "total_epochs = 150\n",
    "patience = 10\n",
    "checkpoint_dir = './checkpoints'\n",
    "\n",
    "# Train the model using the previously defined `train_model` function.\n",
    "train_model(model, train_loader, val_loader, initial_lr=initial_lr,\n",
    "            freeze_epochs=freeze_epochs, total_epochs=total_epochs,\n",
    "            checkpoint_dir=checkpoint_dir, patience=patience, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Load and Evaluate the Best Model\n",
    "\n",
    "After training, load the best saved checkpoint and evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from checkpoint.\n",
      "Validation Loss: 0.8458, IOU: 0.3234, F1: 0.3642\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = '/Users/remiliascarlet/Desktop/MDP/transfer_learning/radburst_tl/training/checkpoints/train_0413/checkpoint_epoch_122_metric_0.8458.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(\"Loaded best model from checkpoint.\")\n",
    "\n",
    "# Evaluate the model on the validation DataLoader\n",
    "val_loss, val_metrics = validate_one_epoch(model, val_loader, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, IOU: {val_metrics['iou']:.4f}, F1: {val_metrics['f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
