{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a UNet Model for Solar Radio Burst Segmentation using PyTorch\n",
    "\n",
    "In this notebook, we demonstrate how to train a UNet model for segmenting solar radio bursts using transfer learning. \n",
    "The training is split into two phases:\n",
    "\n",
    "1. **Phase 1:** Freeze the encoder (pre-trained on ImageNet) and train only the decoder.  \n",
    "2. **Phase 2:** Unfreeze the encoder and fine-tune the entire model using a lower learning rate.\n",
    "\n",
    "We use a combined loss function consisting of binary cross-entropy (BCE) loss and a Jaccard (IOU) loss, and we monitor the IOU and F1 metrics on a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Enhanced Loss Function Setup\n",
    "\n",
    "This notebook now supports the new enhanced loss function system with:\n",
    "- **Focal Loss**: For handling class imbalance (radio bursts are rare)\n",
    "- **Boundary Loss**: For improving edge detection accuracy\n",
    "- **Adaptive IoU Loss**: For better overlap quality assessment\n",
    "\n",
    "The enhanced loss functions are automatically optimized for solar radio burst detection!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 🎯 Import enhanced loss function utilities  \n",
    "# from train_utils import (\n",
    "#     create_dataset, build_unet, freeze_encoder_weights, unfreeze_encoder_weights,\n",
    "#     combined_loss, simple_combined_loss, focal_loss, boundary_loss, adaptive_iou_loss,\n",
    "#     compute_metrics, train_one_epoch, validate_one_epoch, adjust_learning_rate, \n",
    "#     save_checkpoint, train_model\n",
    "# )\n",
    "# from loss_config_example import get_loss_config_for_scenario\n",
    "# from loss_tuner import LossTuner, quick_tune\n",
    "\n",
    "# print(\"🎯 Enhanced loss functions loaded successfully!\")\n",
    "\n",
    "# # Show available loss configurations\n",
    "# configs = [\"balanced\", \"imbalanced\", \"noisy\", \"boundary_critical\"]\n",
    "# print(\"📋 Available loss configurations:\")\n",
    "# for config in configs:\n",
    "#     desc = get_loss_config_for_scenario(config)[\"description\"]\n",
    "#     print(f\"  • {config}: {desc}\")\n",
    "\n",
    "from train_utils_old import (\n",
    "    create_dataset,\n",
    "    build_deeplabv3,      \n",
    "    train_model,          \n",
    "    simple_combined_loss\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Loading and Preprocessing\n",
    "\n",
    "We assume that image and mask CSV files are stored in a single directory.\n",
    "The naming convention is as follows:\n",
    "\n",
    "- For burst slices:\n",
    "       slice_20240608_y155_x270406_SkylineHS.csv\n",
    "       slice_20240608_y155_x270406_SkylineHS_mask.csv\n",
    "\n",
    "- For non-burst slices:\n",
    "       slice_20240420_y0_x3391_PeachMountain_2020_nonburst.csv\n",
    "\n",
    "The `create_dataset` function reads the files, normalizes them to [0, 1], and splits the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (1171, 256, 256, 1)\n",
      "Validation images shape: (293, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/remiliascarlet/Desktop/MDP/transfer_learning/burst_data/csv/saved_slices/25spring'\n",
    "\n",
    "(train_images, train_masks), (val_images, val_masks) = create_dataset(data_dir, img_size=(256, 256), test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Validation images shape:\", val_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create DataLoaders\n",
    "\n",
    "Convert the numpy arrays into PyTorch tensors and create DataLoaders.\n",
    "\n",
    "We also need to permute dimensions from (N, H, W, C) to (N, C, H, W)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert numpy arrays to Torch tensors and permute to (N, channels, H, W)\n",
    "train_images_tensor = torch.tensor(train_images).permute(0, 3, 1, 2)\n",
    "train_masks_tensor  = torch.tensor(train_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "val_images_tensor = torch.tensor(val_images).permute(0, 3, 1, 2)\n",
    "val_masks_tensor  = torch.tensor(val_masks).permute(0, 3, 1, 2)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images_tensor, train_masks_tensor)\n",
    "val_dataset   = TensorDataset(val_images_tensor, val_masks_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Construction\n",
    "\n",
    "Build a UNet model using the `build_unet` function from the segmentation_models library.\n",
    "\n",
    "Here we set `input_shape=(256,256,1)` for grayscale images, `num_classes=1` for binary segmentation,\n",
    "and use pre-trained ImageNet weights with a ResNet34 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): UnetDecoder(\n",
      "    (center): Identity()\n",
      "    (blocks): ModuleList(\n",
      "      (0): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderBlock(\n",
      "        (conv1): Conv2dReLU(\n",
      "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention1): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "        (conv2): Conv2dReLU(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (attention2): Attention(\n",
      "          (attention): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Identity()\n",
      "    (2): Activation(\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import segmentation_models_pytorch library if not already installed: pip install segmentation-models-pytorch\n",
    "# model = build_unet(input_shape=(256, 256, 1), num_classes=1, encoder_weights='imagenet')\n",
    "# model.to(device)\n",
    "\n",
    "# Build UNet from scratch (no ImageNet)\n",
    "model = build_unet(\n",
    "    input_shape=(256, 256, 1), \n",
    "    num_classes=1, \n",
    "    encoder_weights=None        # 🔥 Key: No ImageNet pretraining\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# model = build_deeplabv3(\n",
    "#     input_shape=(256, 256, 1), \n",
    "#     num_classes=1, \n",
    "#     encoder_weights=None,        # 🔥 Key: No ImageNet pretraining\n",
    "#     encoder_name='resnet34'      # Can change to 'resnet18' for faster training\n",
    "# )\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting DeepLabV3+ training with simple loss...\n",
      "   Using BCE + IoU loss (no complex focal/boundary loss)\n",
      "   This focuses on pure architecture comparison\n",
      "✅ Simple configuration ready:\n",
      "   Learning rate: 0.001\n",
      "   Training epochs: 50\n",
      "   No encoder freezing (training from scratch)\n",
      "   Using simple BCE + IoU loss\n",
      "🔧 Using SIMPLE loss function (BCE + IoU only)\n",
      "   No focal loss, boundary loss, or other enhancements\n",
      "   Good for clean model architecture comparison\n",
      "Phase 2: Unfreezing encoder and fine-tuning entire model.\n",
      "Learning rate adjusted to: 0.0001\n",
      "Epoch 1/50 - Train Loss: 1.4106 - Val Loss: 1.3535 - IOU: 0.1939 - F1: 0.2448\n",
      "Checkpoint saved at epoch 1 with best metric 1.3535123938008358 -> ./checkpoints_no_pretrain/checkpoint_epoch_1_metric_1.3535.pth\n",
      "Epoch 2/50 - Train Loss: 1.2927 - Val Loss: 1.3052 - IOU: 0.0920 - F1: 0.1355\n",
      "Checkpoint saved at epoch 2 with best metric 1.3052079112906205 -> ./checkpoints_no_pretrain/checkpoint_epoch_2_metric_1.3052.pth\n",
      "Epoch 3/50 - Train Loss: 1.2358 - Val Loss: 1.1990 - IOU: 0.2090 - F1: 0.2581\n",
      "Checkpoint saved at epoch 3 with best metric 1.1990149711307727 -> ./checkpoints_no_pretrain/checkpoint_epoch_3_metric_1.1990.pth\n",
      "Epoch 4/50 - Train Loss: 1.1611 - Val Loss: 1.1056 - IOU: 0.2195 - F1: 0.2656\n",
      "Checkpoint saved at epoch 4 with best metric 1.1056221096139205 -> ./checkpoints_no_pretrain/checkpoint_epoch_4_metric_1.1056.pth\n",
      "Epoch 5/50 - Train Loss: 1.1190 - Val Loss: 1.0554 - IOU: 0.2369 - F1: 0.2833\n",
      "Checkpoint saved at epoch 5 with best metric 1.0553731102692454 -> ./checkpoints_no_pretrain/checkpoint_epoch_5_metric_1.0554.pth\n",
      "Epoch 6/50 - Train Loss: 1.0987 - Val Loss: 1.3177 - IOU: 0.0562 - F1: 0.0773\n",
      "Epoch 7/50 - Train Loss: 1.0824 - Val Loss: 1.2692 - IOU: 0.0982 - F1: 0.1262\n",
      "Epoch 8/50 - Train Loss: 1.0694 - Val Loss: 1.2165 - IOU: 0.2506 - F1: 0.2934\n",
      "Epoch 9/50 - Train Loss: 1.0263 - Val Loss: 1.1765 - IOU: 0.1503 - F1: 0.1868\n",
      "Epoch 10/50 - Train Loss: 1.0087 - Val Loss: 0.9965 - IOU: 0.2563 - F1: 0.2988\n",
      "Checkpoint saved at epoch 10 with best metric 0.9965246884446395 -> ./checkpoints_no_pretrain/checkpoint_epoch_10_metric_0.9965.pth\n",
      "Epoch 11/50 - Train Loss: 0.9977 - Val Loss: 1.2173 - IOU: 0.2532 - F1: 0.2960\n",
      "Epoch 12/50 - Train Loss: 0.9695 - Val Loss: 1.0748 - IOU: 0.1976 - F1: 0.2416\n",
      "Epoch 13/50 - Train Loss: 0.9551 - Val Loss: 1.1332 - IOU: 0.2578 - F1: 0.3006\n",
      "Epoch 14/50 - Train Loss: 0.9313 - Val Loss: 0.9475 - IOU: 0.2664 - F1: 0.3078\n",
      "Checkpoint saved at epoch 14 with best metric 0.9475453370495847 -> ./checkpoints_no_pretrain/checkpoint_epoch_14_metric_0.9475.pth\n",
      "Epoch 15/50 - Train Loss: 0.9181 - Val Loss: 0.9622 - IOU: 0.2617 - F1: 0.3001\n",
      "Epoch 16/50 - Train Loss: 0.9224 - Val Loss: 0.9743 - IOU: 0.2702 - F1: 0.3124\n",
      "Epoch 17/50 - Train Loss: 0.9164 - Val Loss: 1.0854 - IOU: 0.2103 - F1: 0.2582\n",
      "Epoch 18/50 - Train Loss: 0.8798 - Val Loss: 1.0043 - IOU: 0.2593 - F1: 0.3016\n",
      "Epoch 19/50 - Train Loss: 0.8826 - Val Loss: 0.9428 - IOU: 0.2743 - F1: 0.3169\n",
      "Checkpoint saved at epoch 19 with best metric 0.9427654994161505 -> ./checkpoints_no_pretrain/checkpoint_epoch_19_metric_0.9428.pth\n",
      "Epoch 20/50 - Train Loss: 0.8765 - Val Loss: 0.9397 - IOU: 0.2756 - F1: 0.3207\n",
      "Checkpoint saved at epoch 20 with best metric 0.9397496361481515 -> ./checkpoints_no_pretrain/checkpoint_epoch_20_metric_0.9397.pth\n",
      "Epoch 21/50 - Train Loss: 0.8727 - Val Loss: 1.0619 - IOU: 0.2184 - F1: 0.2630\n",
      "Epoch 22/50 - Train Loss: 0.8589 - Val Loss: 0.9520 - IOU: 0.2711 - F1: 0.3147\n",
      "Epoch 23/50 - Train Loss: 0.8599 - Val Loss: 0.9972 - IOU: 0.2361 - F1: 0.2737\n",
      "Epoch 24/50 - Train Loss: 0.8486 - Val Loss: 0.9566 - IOU: 0.2801 - F1: 0.3217\n",
      "Epoch 25/50 - Train Loss: 0.8396 - Val Loss: 1.0298 - IOU: 0.2738 - F1: 0.3167\n",
      "Epoch 26/50 - Train Loss: 0.8301 - Val Loss: 0.9404 - IOU: 0.2677 - F1: 0.3145\n",
      "Epoch 27/50 - Train Loss: 0.8251 - Val Loss: 0.9435 - IOU: 0.2861 - F1: 0.3295\n",
      "Epoch 28/50 - Train Loss: 0.8018 - Val Loss: 0.9535 - IOU: 0.2677 - F1: 0.3118\n",
      "Epoch 29/50 - Train Loss: 0.7773 - Val Loss: 0.9932 - IOU: 0.2589 - F1: 0.3053\n",
      "Epoch 30/50 - Train Loss: 0.7721 - Val Loss: 1.0416 - IOU: 0.2771 - F1: 0.3207\n",
      "Epoch 31/50 - Train Loss: 0.7752 - Val Loss: 0.9605 - IOU: 0.2668 - F1: 0.3120\n",
      "Epoch 32/50 - Train Loss: 0.7964 - Val Loss: 0.9726 - IOU: 0.2735 - F1: 0.3212\n",
      "Epoch 33/50 - Train Loss: 0.7733 - Val Loss: 0.9320 - IOU: 0.2813 - F1: 0.3235\n",
      "Checkpoint saved at epoch 33 with best metric 0.931982021582754 -> ./checkpoints_no_pretrain/checkpoint_epoch_33_metric_0.9320.pth\n",
      "Epoch 34/50 - Train Loss: 0.7682 - Val Loss: 0.9256 - IOU: 0.2860 - F1: 0.3297\n",
      "Checkpoint saved at epoch 34 with best metric 0.925596325021041 -> ./checkpoints_no_pretrain/checkpoint_epoch_34_metric_0.9256.pth\n",
      "Epoch 35/50 - Train Loss: 0.7574 - Val Loss: 0.9278 - IOU: 0.2856 - F1: 0.3280\n",
      "Epoch 36/50 - Train Loss: 0.7549 - Val Loss: 1.0648 - IOU: 0.2758 - F1: 0.3192\n",
      "Epoch 37/50 - Train Loss: 0.7293 - Val Loss: 0.9363 - IOU: 0.2790 - F1: 0.3244\n",
      "Epoch 38/50 - Train Loss: 0.7413 - Val Loss: 1.0170 - IOU: 0.2562 - F1: 0.3024\n",
      "Epoch 39/50 - Train Loss: 0.7228 - Val Loss: 0.9923 - IOU: 0.2939 - F1: 0.3388\n",
      "Epoch 40/50 - Train Loss: 0.7376 - Val Loss: 0.9331 - IOU: 0.2873 - F1: 0.3315\n",
      "Epoch 41/50 - Train Loss: 0.7291 - Val Loss: 0.9765 - IOU: 0.2778 - F1: 0.3189\n",
      "Epoch 42/50 - Train Loss: 0.7422 - Val Loss: 1.0136 - IOU: 0.2481 - F1: 0.2940\n",
      "Epoch 43/50 - Train Loss: 0.7012 - Val Loss: 0.9253 - IOU: 0.2897 - F1: 0.3337\n",
      "Checkpoint saved at epoch 43 with best metric 0.9252566161908602 -> ./checkpoints_no_pretrain/checkpoint_epoch_43_metric_0.9253.pth\n",
      "Epoch 44/50 - Train Loss: 0.7293 - Val Loss: 0.9729 - IOU: 0.2877 - F1: 0.3333\n",
      "Epoch 45/50 - Train Loss: 0.6903 - Val Loss: 0.9191 - IOU: 0.3009 - F1: 0.3433\n",
      "Checkpoint saved at epoch 45 with best metric 0.9191254596961173 -> ./checkpoints_no_pretrain/checkpoint_epoch_45_metric_0.9191.pth\n",
      "Epoch 46/50 - Train Loss: 0.7183 - Val Loss: 1.0398 - IOU: 0.2452 - F1: 0.2957\n",
      "Epoch 47/50 - Train Loss: 0.6930 - Val Loss: 0.9410 - IOU: 0.2873 - F1: 0.3301\n",
      "Epoch 48/50 - Train Loss: 0.7089 - Val Loss: 0.9627 - IOU: 0.2811 - F1: 0.3255\n",
      "Epoch 49/50 - Train Loss: 0.6928 - Val Loss: 0.9884 - IOU: 0.2795 - F1: 0.3231\n"
     ]
    }
   ],
   "source": [
    "# 🚀 DeepLabV3+ Training with Simple Loss Function\n",
    "print(\"🚀 Starting DeepLabV3+ training with simple loss...\")\n",
    "print(\"   Using BCE + IoU loss (no complex focal/boundary loss)\")\n",
    "print(\"   This focuses on pure architecture comparison\")\n",
    "\n",
    "# Simple training configuration for DeepLabV3+\n",
    "training_config_simple = {\n",
    "    'initial_lr': 1e-3,       # Standard learning rate\n",
    "    'freeze_epochs': 0,       # No freezing needed (no ImageNet pretraining)\n",
    "    'total_epochs': 50,       # Can be increased for better results\n",
    "    'patience': 15,           # More patience due to training from scratch\n",
    "    'checkpoint_dir': './checkpoints_no_pretrain'\n",
    "}\n",
    "\n",
    "print(\"✅ Simple configuration ready:\")\n",
    "print(f\"   Learning rate: {training_config_simple['initial_lr']}\")\n",
    "print(f\"   Training epochs: {training_config_simple['total_epochs']}\")\n",
    "print(f\"   No encoder freezing (training from scratch)\")\n",
    "print(f\"   Using simple BCE + IoU loss\")\n",
    "\n",
    "# Train the model with simple loss function\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    initial_lr=training_config_simple['initial_lr'],\n",
    "    freeze_epochs=training_config_simple['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "    total_epochs=training_config_simple['total_epochs'],\n",
    "    checkpoint_dir=training_config_simple['checkpoint_dir'],\n",
    "    patience=training_config_simple['patience'],\n",
    "    device=device\n",
    "    # 注意：没有 loss_weights, focal_params 等复杂参数\n",
    "    # 自动使用 simple_combined_loss (BCE + IoU)\n",
    ")\n",
    "\n",
    "print(\"✅ Training completed!\")\n",
    "\n",
    "# 📊 Quick Results Analysis\n",
    "if history:\n",
    "    final_metrics = history[-1]\n",
    "    final_f1 = final_metrics.get('val_f1', 0)\n",
    "    final_iou = final_metrics.get('val_iou', 0)\n",
    "    \n",
    "    print(f\"\\n🎯 DeepLabV3+ + Simple Loss Results:\")\n",
    "    print(f\"   Final F1 Score: {final_f1:.4f}\")\n",
    "    print(f\"   Final IoU Score: {final_iou:.4f}\")\n",
    "    \n",
    "    # Compare with your baseline\n",
    "    baseline_f1 = 0.27  # Your UNet + ImageNet result\n",
    "    improvement = final_f1 - baseline_f1\n",
    "    \n",
    "    print(f\"\\n📈 vs UNet+ImageNet baseline:\")\n",
    "    print(f\"   Baseline F1: {baseline_f1:.4f}\")\n",
    "    print(f\"   DeepLabV3+ F1: {final_f1:.4f}\")\n",
    "    print(f\"   Improvement: +{improvement:.4f} ({(improvement/baseline_f1)*100:.1f}%)\")\n",
    "    \n",
    "    if final_f1 > 0.35:\n",
    "        print(\"   🎉 Excellent! Clear architecture improvement\")\n",
    "    elif final_f1 > 0.3:\n",
    "        print(\"   👍 Good improvement! DeepLabV3+ is working\")\n",
    "    else:\n",
    "        print(\"   🤔 Need investigation - try different backbone or more epochs\")\n",
    "else:\n",
    "    print(\"❌ No training history available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔧 Enhanced Training with Loss Function Tuning\n",
    "\n",
    "The training functions now automatically use enhanced loss functions optimized for radio burst detection. You can also customize the loss parameters based on your specific needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Loss Function Configuration Options\n",
    "print(\"🎯 Enhanced Loss Function Configuration\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Option 1: Use predefined scenarios (RECOMMENDED)\n",
    "print(\"📋 Option 1: Predefined Scenarios\")\n",
    "scenarios = {\n",
    "    \"imbalanced\": \"Sparse positive samples (recommended for radio bursts)\",  \n",
    "    \"balanced\": \"Roughly balanced positive/negative samples\",\n",
    "    \"noisy\": \"Significant noise and artifacts in data\",\n",
    "    \"boundary_critical\": \"High precision required for edge detection\",\n",
    "    \"original\": \"Use simple BCE+IoU loss (backward compatibility)\"\n",
    "}\n",
    "\n",
    "for scenario, description in scenarios.items():\n",
    "    config = get_loss_config_for_scenario(scenario)\n",
    "    print(f\"  • {scenario}: {description}\")\n",
    "    if not config.get('use_simple_loss', False):\n",
    "        print(f\"    Weights: {config['loss_weights']}\")\n",
    "        print(f\"    Focal: {config['focal_params']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Option 2: Custom parameters\n",
    "print(\"🔧 Option 2: Custom Parameters\")\n",
    "print(\"  You can specify custom loss_weights and focal_params in train_model()\")\n",
    "print(\"  Example:\")\n",
    "print(\"    loss_weights = {'focal': 1.5, 'iou': 1.2, 'boundary': 0.3}\")\n",
    "print(\"    focal_params = {'alpha': 0.85, 'gamma': 3.0}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Option 3: Auto-tuning based on validation metrics\n",
    "print(\"📊 Option 3: Auto-tuning (Advanced)\")\n",
    "print(\"  Use LossTuner to get suggestions based on validation metrics\")\n",
    "example_metrics = {'precision': 0.85, 'recall': 0.45, 'f1': 0.59, 'iou': 0.42}\n",
    "print(f\"  Example: {example_metrics}\")\n",
    "\n",
    "# Uncomment to use auto-tuning:\n",
    "# tuner = LossTuner()\n",
    "# suggested = tuner.suggest_parameters(example_metrics)\n",
    "# print(f\"  Suggested: {suggested}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 DeepLabV3+ Training Configuration\n",
    "print(\"⚙️ Configuring training parameters for DeepLabV3+...\")\n",
    "\n",
    "# Training parameters optimized for DeepLabV3+\n",
    "training_config_deeplabv3 = {\n",
    "    'initial_lr': 1e-3,       # Standard learning rate\n",
    "    'freeze_epochs': 0,       # No freezing needed (no ImageNet)\n",
    "    'total_epochs': 50,       # Can be increased for better results\n",
    "    'patience': 15,           # More patience due to no pretraining\n",
    "    'loss_config': 'imbalanced'  # Use predefined imbalanced configuration\n",
    "}\n",
    "\n",
    "print(\"✅ Configuration ready:\")\n",
    "print(f\"   Loss weights: {loss_config_deeplabv3}\")\n",
    "print(f\"   Training epochs: {training_config_deeplabv3['total_epochs']}\")\n",
    "print(f\"   No encoder freezing (training from scratch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Training with Configurable Loss Parameters\n",
    "# initial_lr = 1e-3\n",
    "# freeze_epochs = 100\n",
    "# total_epochs = 150\n",
    "# patience = 10\n",
    "# checkpoint_dir = './checkpoints_enhanced'\n",
    "\n",
    "print(\"🚀 Starting Enhanced Training with Configurable Loss...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Choose your training method:\n",
    "\n",
    "# # Method A: Use predefined scenario (RECOMMENDED)\n",
    "# loss_config = \"imbalanced\"  # Choose: \"balanced\", \"imbalanced\", \"noisy\", \"boundary_critical\", \"original\"\n",
    "\n",
    "# train_model(model, train_loader, val_loader, \n",
    "#            initial_lr=initial_lr,\n",
    "#            freeze_epochs=freeze_epochs, \n",
    "#            total_epochs=total_epochs,\n",
    "#            checkpoint_dir=checkpoint_dir, \n",
    "#            patience=patience, \n",
    "#            device=device,\n",
    "#            loss_config=loss_config)\n",
    "\n",
    "# Method B: Use custom parameters (ADVANCED)\n",
    "# custom_loss_weights = {'focal': 1.5, 'iou': 1.2, 'boundary': 0.3}\n",
    "# custom_focal_params = {'alpha': 0.85, 'gamma': 3.0}\n",
    "# \n",
    "# train_model(model, train_loader, val_loader, \n",
    "#            initial_lr=initial_lr,\n",
    "#            freeze_epochs=freeze_epochs, \n",
    "#            total_epochs=total_epochs,\n",
    "#            checkpoint_dir=checkpoint_dir, \n",
    "#            patience=patience, \n",
    "#            device=device,\n",
    "#            loss_weights=custom_loss_weights,\n",
    "#            focal_params=custom_focal_params)\n",
    "\n",
    "# Train with enhanced loss configuration\n",
    "trained_model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    initial_lr=training_config_deeplabv3['initial_lr'],\n",
    "    freeze_epochs=training_config_deeplabv3['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "    total_epochs=training_config_deeplabv3['total_epochs'],\n",
    "    checkpoint_dir='./checkpoints_deeplabv3',  # Separate directory\n",
    "    patience=training_config_deeplabv3['patience'],\n",
    "    device=device,\n",
    "    loss_config=training_config_deeplabv3['loss_config']  # Use imbalanced config\n",
    ")\n",
    "\n",
    "# Method B: Custom DeepLabV3+ parameters (ADVANCED)\n",
    "# custom_loss_weights = {'focal': 0.8, 'iou': 1.0, 'boundary': 0.2}  # Adjust weights\n",
    "# custom_focal_params = {'alpha': 0.85, 'gamma': 2.5}                # Fine-tune focal loss\n",
    "# custom_backbone = 'resnet18'  # 'resnet18', 'resnet34', 'efficientnet-b0'\n",
    "# \n",
    "# # Rebuild model with custom backbone if needed\n",
    "# # model = build_deeplabv3(encoder_name=custom_backbone, encoder_weights=None)\n",
    "# # model.to(device)\n",
    "# \n",
    "# trained_model, history = train_model(\n",
    "#     model=model,\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     initial_lr=training_config_deeplabv3['initial_lr'],\n",
    "#     freeze_epochs=training_config_deeplabv3['freeze_epochs'],  # 0 for DeepLabV3+\n",
    "#     total_epochs=training_config_deeplabv3['total_epochs'],\n",
    "#     checkpoint_dir='./checkpoints_deeplabv3',  # Separate directory\n",
    "#     patience=training_config_deeplabv3['patience'],\n",
    "#     device=device,\n",
    "#     loss_weights=custom_loss_weights,\n",
    "#     focal_params=custom_focal_params\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Enhanced vs Original Loss Comparison\n",
    "\n",
    "Load and Evaluate the Best Model\n",
    "\n",
    "After training, load the best saved checkpoint and evaluate the model on the validation set.\n",
    "\n",
    "You can compare the enhanced loss function with the original BCE+IoU loss to see the improvement:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best enhanced model and compare with original loss\n",
    "print(\"🔍 Comparing Enhanced vs Original Loss Functions\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the enhanced model\n",
    "best_enhanced_path = './checkpoints_enhanced/[your_best_checkpoint].pth'  # Update this path\n",
    "# checkpoint = torch.load(best_enhanced_path, map_location=device)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Evaluate with enhanced loss (already loaded)\n",
    "print(\"📊 Enhanced Loss Results:\")\n",
    "val_loss_enhanced, val_metrics_enhanced = validate_one_epoch(model, val_loader, device)\n",
    "print(f\"  Validation Loss: {val_loss_enhanced:.4f}\")\n",
    "print(f\"  IoU: {val_metrics_enhanced['iou']:.4f}\")\n",
    "print(f\"  F1:  {val_metrics_enhanced['f1']:.4f}\")\n",
    "\n",
    "# For comparison, evaluate with original loss\n",
    "print(\"\\\\n📊 Original Loss (BCE+IoU) for comparison:\")\n",
    "model.eval()\n",
    "total_original_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds = model(x)\n",
    "        # Use original simple loss\n",
    "        original_loss = simple_combined_loss(y, preds)\n",
    "        total_original_loss += original_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "avg_original_loss = total_original_loss / num_batches\n",
    "print(f\"  Original Loss: {avg_original_loss:.4f}\")\n",
    "print(f\"  IoU: {val_metrics_enhanced['iou']:.4f} (same model)\")\n",
    "print(f\"  F1:  {val_metrics_enhanced['f1']:.4f} (same model)\")\n",
    "\n",
    "# Show improvement\n",
    "improvement = avg_original_loss - val_loss_enhanced\n",
    "improvement_pct = improvement / avg_original_loss * 100\n",
    "print(f\"\\\\n🎯 Loss Improvement: {improvement:.4f} ({improvement_pct:+.1f}%)\")\n",
    "\n",
    "# Individual loss component analysis\n",
    "print(f\"\\\\n🧩 Enhanced Loss Component Breakdown:\")\n",
    "with torch.no_grad():\n",
    "    sample_x, sample_y = next(iter(val_loader))\n",
    "    sample_x, sample_y = sample_x.to(device), sample_y.to(device)\n",
    "    sample_preds = model(sample_x)\n",
    "    \n",
    "    focal_val = focal_loss(sample_preds, sample_y, alpha=0.8, gamma=2.5)\n",
    "    iou_val = adaptive_iou_loss(sample_preds, sample_y, power=1.5)\n",
    "    boundary_val = boundary_loss(sample_preds, sample_y)\n",
    "    \n",
    "    print(f\"  Focal Loss:    {focal_val.item():.4f}\")\n",
    "    print(f\"  IoU Loss:      {iou_val.item():.4f}\")\n",
    "    print(f\"  Boundary Loss: {boundary_val.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
